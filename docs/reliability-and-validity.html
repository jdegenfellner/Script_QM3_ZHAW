<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Reliability and Validity | Quantitative Methods 3, ZHAW</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Reliability and Validity | Quantitative Methods 3, ZHAW" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Reliability and Validity | Quantitative Methods 3, ZHAW" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Jürgen Degenfellner" />


<meta name="date" content="2025-04-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet" />
<script src="libs/tabwid-1.1.3/tabwid.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Quantitative Methods 3</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preamble</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#books-we-will-heavily-borrow-from-are"><i class="fa fa-check"></i><b>1.1</b> Books we will heavily borrow from are:</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#if-you-need-a-good-reason-to-buy-great-books"><i class="fa fa-check"></i><b>1.2</b> If you need a good reason to buy great books…</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html"><i class="fa fa-check"></i><b>2</b> Reliability and Validity</a>
<ul>
<li class="chapter" data-level="2.1" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#reliability"><i class="fa fa-check"></i><b>2.1</b> Reliability</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#peter-and-marys-rom-measurements"><i class="fa fa-check"></i><b>2.1.1</b> Peter and Mary’s ROM measurements</a></li>
<li class="chapter" data-level="2.1.2" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#intraclass-correlation-coefficient-icc"><i class="fa fa-check"></i><b>2.1.2</b> Intraclass Correlation Coefficient (ICC)</a></li>
<li class="chapter" data-level="2.1.3" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#explanation-of-iccs-in-the-psych-output"><i class="fa fa-check"></i><b>2.1.3</b> Explanation of ICCs in the <code>psych</code> output</a></li>
<li class="chapter" data-level="2.1.4" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#summary-peter-and-mary-with-and-without-bias"><i class="fa fa-check"></i><b>2.1.4</b> Summary Peter and Mary, with and without bias</a></li>
<li class="chapter" data-level="2.1.5" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#difference-between-correlation-and-icc"><i class="fa fa-check"></i><b>2.1.5</b> Difference between correlation and ICC</a></li>
<li class="chapter" data-level="2.1.6" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#bad-news-about-the-icc"><i class="fa fa-check"></i><b>2.1.6</b> Bad news about the ICC?</a></li>
<li class="chapter" data-level="2.1.7" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#standard-error-of-measurement-sem"><i class="fa fa-check"></i><b>2.1.7</b> Standard Error of Measurement (SEM)</a></li>
<li class="chapter" data-level="2.1.8" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#bland-altman-plot"><i class="fa fa-check"></i><b>2.1.8</b> Bland-Altman Plot</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#validity"><i class="fa fa-check"></i><b>2.2</b> Validity</a></li>
<li class="chapter" data-level="2.3" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#todos"><i class="fa fa-check"></i><b>2.3</b> TODOS</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Quantitative Methods 3, ZHAW</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="reliability-and-validity" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Reliability and Validity<a href="reliability-and-validity.html#reliability-and-validity" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>For this chapter we refer to the book
<a href="https://www.cambridge.org/core/books/measurement-in-medicine/8BD913A1DA0ECCBA951AC4C1F719BCC5">Measurement in Medicine</a>.</p>
<p>I invite you to read the introductory chapters 1 and 2 about concepts,
theories and models, and types of measurement.</p>
<p>In general, when conducting a measurement of any sort
(laboratory measurements, scores from questionnaires, etc.),
we want to be reasonably sure</p>
<ul>
<li>that we actually <strong>measure what we intend to measure</strong>;
(<a href="https://en.wikipedia.org/wiki/Validity_(statistics)">validity</a>;
chapter 6 in the book);</li>
<li>that the measurement does <strong>not change too much</strong> if the
underlying <strong>conditions are the same</strong>
(<a href="https://en.wikipedia.org/wiki/Reliability_(statistics)">reliability</a>;
chapter 5 in the book); and</li>
<li>that we are able to detect a <strong>change</strong> if the underlying conditions change
(<a href="https://tinyurl.com/3vdcxy49">responsiveness</a>; chapter 7 in the book); and</li>
<li>that we understand the meaning of a change in the measurement
(interpretability; chapter 8 in the book).</li>
</ul>
<p>In this <a href="https://www.youtube.com/watch?v=KuT2n1w0Ixc&amp;ab_channel=Physiotutors">video</a>,
Kai jump starts you on reliability and validity.</p>
<div id="reliability" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Reliability<a href="reliability-and-validity.html#reliability" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>You can watch this <a href="https://www.youtube.com/watch?v=9HSoWaRpcys&amp;ab_channel=Physiotutors">video</a>
to get started.</p>
<p>Imagine, you measure a patient (pick your favorite measurement), for example,
the range of motion (ROM) of the shoulder.</p>
<ul>
<li>If you are interested in how
similar your measurements are in comparison to your colleagues, you are
trying to determine the so-called <strong>inter-rater reliability</strong>.</li>
<li>If you are interested in how similar your measurements are when you measure
the same patient twice, you are trying to determine the so-called
<strong>intra-rater reliability</strong>.</li>
</ul>
<p>Assuming there is a true (but unknown) underlying value (of Range of Motion, ROM),
it is clear that measurements will not be <em>exactly</em> the same.
Possible influences (potentially) causing different results are:</p>
<ul>
<li>the measurement instrument itself (e.g., the goniometer),</li>
<li>the patient (e.g., mood/motivation),</li>
<li>the examiner (e.g., mood, influence on patient),</li>
<li>the environment (e.g., the room temperature).</li>
</ul>
<p>Note that the <strong>true score</strong> is defined in our context as the average of all measurements
if we would measure repeatedly an infinite number of times.</p>
<div id="peter-and-marys-rom-measurements" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Peter and Mary’s ROM measurements<a href="reliability-and-validity.html#peter-and-marys-rom-measurements" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The data can be found <a href="http://www.clinimetrics.nl/answers-to-the-assignments-in-textbook_22_0.html">here</a>.
We randomly select 50 measurements from Peter and Mary in 50 different patients,
plot their measurements and annotate the absolutely largest one(s). At first the
<em>not affected shoulder</em> (nas) and then the <em>affected shoulder</em> (as).</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="reliability-and-validity.html#cb1-1" tabindex="-1"></a><span class="fu">library</span>(pacman)</span>
<span id="cb1-2"><a href="reliability-and-validity.html#cb1-2" tabindex="-1"></a><span class="fu">p_load</span>(tidyverse, readxl)</span>
<span id="cb1-3"><a href="reliability-and-validity.html#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="reliability-and-validity.html#cb1-4" tabindex="-1"></a><span class="co"># Read file</span></span>
<span id="cb1-5"><a href="reliability-and-validity.html#cb1-5" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="st">&quot;https://raw.githubusercontent.com/jdegenfellner/Script_QM2_ZHAW/main/data/chapter%205_assignment%201_2_wide.xls&quot;</span></span>
<span id="cb1-6"><a href="reliability-and-validity.html#cb1-6" tabindex="-1"></a>temp_file <span class="ot">&lt;-</span> <span class="fu">tempfile</span>(<span class="at">fileext =</span> <span class="st">&quot;.xls&quot;</span>)</span>
<span id="cb1-7"><a href="reliability-and-validity.html#cb1-7" tabindex="-1"></a><span class="fu">download.file</span>(url, temp_file, <span class="at">mode =</span> <span class="st">&quot;wb&quot;</span>)  <span class="co"># mode=&quot;wb&quot; is important for binary files</span></span>
<span id="cb1-8"><a href="reliability-and-validity.html#cb1-8" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(temp_file)</span>
<span id="cb1-9"><a href="reliability-and-validity.html#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="reliability-and-validity.html#cb1-10" tabindex="-1"></a><span class="fu">head</span>(df)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 5
##   patcode ROMnas.Mary ROMnas.Peter ROMas.Mary ROMas.Peter
##     &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;
## 1       1          90           92         88          95
## 2       2          82           88         82          90
## 3       3          82           88         57          59
## 4       4          89           89         82          81
## 5       5          80           82         48          40
## 6       6          90           96         99          85</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="reliability-and-validity.html#cb3-1" tabindex="-1"></a><span class="fu">dim</span>(df)</span></code></pre></div>
<pre><code>## [1] 155   5</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="reliability-and-validity.html#cb5-1" tabindex="-1"></a><span class="co"># As in the book, let&#39;s randomly select 50 patients.</span></span>
<span id="cb5-2"><a href="reliability-and-validity.html#cb5-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb5-3"><a href="reliability-and-validity.html#cb5-3" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> <span class="fu">sample_n</span>(<span class="dv">50</span>)</span>
<span id="cb5-4"><a href="reliability-and-validity.html#cb5-4" tabindex="-1"></a><span class="fu">dim</span>(df)</span></code></pre></div>
<pre><code>## [1] 50  5</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="reliability-and-validity.html#cb7-1" tabindex="-1"></a><span class="co"># &quot;as&quot; = affected shoulder</span></span>
<span id="cb7-2"><a href="reliability-and-validity.html#cb7-2" tabindex="-1"></a><span class="co"># &quot;nas&quot; = not affected shoulder</span></span>
<span id="cb7-3"><a href="reliability-and-validity.html#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="reliability-and-validity.html#cb7-4" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb7-5"><a href="reliability-and-validity.html#cb7-5" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">diff =</span> <span class="fu">abs</span>(ROMnas.Peter <span class="sc">-</span> ROMnas.Mary))  <span class="co"># Compute absolute difference</span></span>
<span id="cb7-6"><a href="reliability-and-validity.html#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="reliability-and-validity.html#cb7-7" tabindex="-1"></a>max_diff_point <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb7-8"><a href="reliability-and-validity.html#cb7-8" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(diff <span class="sc">==</span> <span class="fu">max</span>(diff, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))  <span class="co"># Find the row with the max difference</span></span>
<span id="cb7-9"><a href="reliability-and-validity.html#cb7-9" tabindex="-1"></a></span>
<span id="cb7-10"><a href="reliability-and-validity.html#cb7-10" tabindex="-1"></a>df <span class="sc">%&gt;%</span></span>
<span id="cb7-11"><a href="reliability-and-validity.html#cb7-11" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> ROMnas.Peter, <span class="at">y =</span> ROMnas.Mary)) <span class="sc">+</span></span>
<span id="cb7-12"><a href="reliability-and-validity.html#cb7-12" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb7-13"><a href="reliability-and-validity.html#cb7-13" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> max_diff_point, <span class="fu">aes</span>(<span class="at">x =</span> ROMnas.Peter, <span class="at">y =</span> ROMnas.Mary), </span>
<span id="cb7-14"><a href="reliability-and-validity.html#cb7-14" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span>  <span class="co"># Highlight max difference point</span></span>
<span id="cb7-15"><a href="reliability-and-validity.html#cb7-15" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb7-16"><a href="reliability-and-validity.html#cb7-16" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb7-17"><a href="reliability-and-validity.html#cb7-17" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;ROMnas.Peter vs. ROMnas.Mary&quot;</span>) <span class="sc">+</span></span>
<span id="cb7-18"><a href="reliability-and-validity.html#cb7-18" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb7-19"><a href="reliability-and-validity.html#cb7-19" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="at">x =</span> max_diff_point<span class="sc">$</span>ROMnas.Peter, </span>
<span id="cb7-20"><a href="reliability-and-validity.html#cb7-20" tabindex="-1"></a>           <span class="at">y =</span> max_diff_point<span class="sc">$</span>ROMnas.Mary, </span>
<span id="cb7-21"><a href="reliability-and-validity.html#cb7-21" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste0</span>(<span class="st">&quot;Max Diff: &quot;</span>, <span class="fu">round</span>(max_diff_point<span class="sc">$</span>diff, <span class="dv">2</span>)), </span>
<span id="cb7-22"><a href="reliability-and-validity.html#cb7-22" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">size =</span> <span class="dv">4</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="reliability-and-validity.html#cb8-1" tabindex="-1"></a><span class="co"># average abs. difference:</span></span>
<span id="cb8-2"><a href="reliability-and-validity.html#cb8-2" tabindex="-1"></a><span class="fu">mean</span>(df<span class="sc">$</span>diff, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) <span class="co"># 7.2</span></span></code></pre></div>
<pre><code>## [1] 7.2</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="reliability-and-validity.html#cb10-1" tabindex="-1"></a><span class="fu">cor</span>(df<span class="sc">$</span>ROMnas.Peter, df<span class="sc">$</span>ROMnas.Mary, <span class="at">use =</span> <span class="st">&quot;complete.obs&quot;</span>) </span></code></pre></div>
<pre><code>## [1] 0.2403213</code></pre>
<p>The red line represents the line of equality (<span class="math inline">\(y=x\)</span>). If the measurements are
exactly the same,
all points would lie on this line. The blue point represents the largest
absolute difference in measured Range of Motion (ROM) values between Peter and Mary
from the randomly chosen 50 people. Note that the maximum difference in
all 155 patients is 35 degrees.</p>
<p>The first simple measure of agreement we could use is the (Pearson) correlation, which
measures the <strong>strength and direction of a linear relationship between two variables</strong>.
But correlation does not exactly measure what we want. If there was a bias
(e.g., Mary systematically measures 5 degrees more than Peter), correlation would not
notice this. (-&gt; exercise later…). It actually is too optimistic about
the agreement since it only cares about the linearity and not about a potential bias.
<span class="math inline">\(r=0.2403213\)</span> which indicates a weak positive correlation. Higher values of Peter’s
are associated with higher values of Mary’s measurements.
But: Knowing Peter’s measurement does not help us to <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#Interpretation_of_the_size_of_a_correlation"><em>predict</em></a>
Mary’s measurement at such a low correlation (-&gt; exercise later).
So, on the <em>not affected shoulder</em> (nas), agreement is really bad.</p>
<p>What about the affected shoulder (as)?</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="reliability-and-validity.html#cb12-1" tabindex="-1"></a><span class="fu">library</span>(ggExtra)</span>
<span id="cb12-2"><a href="reliability-and-validity.html#cb12-2" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb12-3"><a href="reliability-and-validity.html#cb12-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">diff =</span> <span class="fu">abs</span>(ROMas.Peter <span class="sc">-</span> ROMas.Mary))  <span class="co"># Compute absolute difference</span></span>
<span id="cb12-4"><a href="reliability-and-validity.html#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a href="reliability-and-validity.html#cb12-5" tabindex="-1"></a>max_diff_point <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb12-6"><a href="reliability-and-validity.html#cb12-6" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(diff <span class="sc">==</span> <span class="fu">max</span>(diff, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))  <span class="co"># Find the row with the max difference</span></span>
<span id="cb12-7"><a href="reliability-and-validity.html#cb12-7" tabindex="-1"></a></span>
<span id="cb12-8"><a href="reliability-and-validity.html#cb12-8" tabindex="-1"></a>p <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb12-9"><a href="reliability-and-validity.html#cb12-9" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> ROMas.Peter, <span class="at">y =</span> ROMas.Mary)) <span class="sc">+</span></span>
<span id="cb12-10"><a href="reliability-and-validity.html#cb12-10" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb12-11"><a href="reliability-and-validity.html#cb12-11" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> max_diff_point, <span class="fu">aes</span>(<span class="at">x =</span> ROMas.Peter, <span class="at">y =</span> ROMas.Mary), </span>
<span id="cb12-12"><a href="reliability-and-validity.html#cb12-12" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span>  <span class="co"># Highlight max difference point</span></span>
<span id="cb12-13"><a href="reliability-and-validity.html#cb12-13" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb12-14"><a href="reliability-and-validity.html#cb12-14" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb12-15"><a href="reliability-and-validity.html#cb12-15" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;ROMas.Peter vs. ROMas.Mary&quot;</span>) <span class="sc">+</span></span>
<span id="cb12-16"><a href="reliability-and-validity.html#cb12-16" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb12-17"><a href="reliability-and-validity.html#cb12-17" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="at">x =</span> max_diff_point<span class="sc">$</span>ROMas.Peter, </span>
<span id="cb12-18"><a href="reliability-and-validity.html#cb12-18" tabindex="-1"></a>           <span class="at">y =</span> max_diff_point<span class="sc">$</span>ROMas.Mary, </span>
<span id="cb12-19"><a href="reliability-and-validity.html#cb12-19" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste0</span>(<span class="st">&quot;Max Diff: &quot;</span>, <span class="fu">round</span>(max_diff_point<span class="sc">$</span>diff, <span class="dv">2</span>)), </span>
<span id="cb12-20"><a href="reliability-and-validity.html#cb12-20" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">size =</span> <span class="dv">4</span>)</span>
<span id="cb12-21"><a href="reliability-and-validity.html#cb12-21" tabindex="-1"></a><span class="co"># Add marginal histograms</span></span>
<span id="cb12-22"><a href="reliability-and-validity.html#cb12-22" tabindex="-1"></a><span class="fu">ggMarginal</span>(p, <span class="at">type =</span> <span class="st">&quot;density&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;gray&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="reliability-and-validity.html#cb13-1" tabindex="-1"></a><span class="co"># average abs. difference:</span></span>
<span id="cb13-2"><a href="reliability-and-validity.html#cb13-2" tabindex="-1"></a><span class="fu">mean</span>(df<span class="sc">$</span>diff, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) <span class="co"># 7.2</span></span></code></pre></div>
<pre><code>## [1] 7.78</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="reliability-and-validity.html#cb15-1" tabindex="-1"></a><span class="fu">cor</span>(df<span class="sc">$</span>ROMas.Peter, df<span class="sc">$</span>ROMas.Mary, <span class="at">use =</span> <span class="st">&quot;complete.obs&quot;</span>) </span></code></pre></div>
<pre><code>## [1] 0.8516653</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="reliability-and-validity.html#cb17-1" tabindex="-1"></a><span class="co"># mean difference</span></span>
<span id="cb17-2"><a href="reliability-and-validity.html#cb17-2" tabindex="-1"></a><span class="fu">mean</span>(df<span class="sc">$</span>ROMas.Peter <span class="sc">-</span> df<span class="sc">$</span>ROMas.Mary, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) </span></code></pre></div>
<pre><code>## [1] 1.22</code></pre>
<p>In the affected side, the average absolute difference is even larger (<span class="math inline">\(7.78\)</span>)
with a maximum absolute difference of 37 degrees,
but the correlation is much higher (<span class="math inline">\(r=0.8516653\)</span>). See Figure 5.2 in the book.</p>
<p>Btw, this is an an example for using the correlation coefficient even though
the marginal distributions are not normal: There are much more measurements in the higher
values around 80 than below, say, 60. But the correlation coefficient makes sense
for descriptive purposes.</p>
<p>In this case, knowing Peter’s measurement <em>does</em> help us to predict
Mary’s measurement (-&gt; exercise later).</p>
</div>
<div id="intraclass-correlation-coefficient-icc" class="section level3 hasAnchor" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> Intraclass Correlation Coefficient (ICC)<a href="reliability-and-validity.html#intraclass-correlation-coefficient-icc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One way to measure reliability is to use the intraclass correlation coefficient (ICC).</p>
<p>This measure is based on the idea that the observed score <span class="math inline">\(Y_i\)</span> consists of the true score
(ROM) (<span class="math inline">\(\eta_i\)</span>) and a measurement error (for each person).
The proportion of the true score variability to the total variability is the ICC.</p>
<p>In the background one thinks of a statistical model from the
<a href="https://en.wikipedia.org/wiki/Classical_test_theory">Classical Test Theory (CTT)</a>.
There is</p>
<ul>
<li>a true underlying score <span class="math inline">\(\eta_i\)</span> (for each patient i) and</li>
<li>an error term <span class="math inline">\(\varepsilon_i \sim N(0, \sigma_i)\)</span> which is the difference between the true
score and</li>
<li>the observed score <span class="math inline">\(Y_i\)</span>.</li>
</ul>
<p><span class="math display">\[Y_i = \eta_i + \varepsilon_i\]</span></p>
<p>It is assumed that <span class="math inline">\(\eta_i\)</span> and <span class="math inline">\(\varepsilon_i\)</span> are independent: (<span class="math inline">\(\mathbb{C}ov(\eta_i, \varepsilon_i)=0\)</span>).
This is a nice assumption because now we know (see <a href="https://en.wikipedia.org/wiki/Variance#Addition_and_multiplication_by_a_constant">here</a>)
that the variance
of the observed score <span class="math inline">\(Y_i\)</span> is just the sum of the variance of the true score <span class="math inline">\(\eta_i\)</span>
and the variance of the error term <span class="math inline">\(\varepsilon_i\)</span>:</p>
<p><span class="math display">\[\mathbb{V}ar(Y_i) = \mathbb{V}ar(\eta_i) + \mathbb{V}ar(\varepsilon_i)\]</span>
<span class="math display">\[\sigma_{Y_i}^2 = \sigma_{\eta_i}^2 + \sigma_{\varepsilon_i}^2\]</span></p>
<p>We want most of the variability in our observed scores <span class="math inline">\(Y_i\)</span> to be explained by the
true but unobservable scores <span class="math inline">\(\eta_i\)</span>. The measurement error <span class="math inline">\(\varepsilon_i\)</span> should be
be comparatively small. If it is large, we are mostly measuring noise or at least not
what we want to measure.</p>
<p><strong>How do we get to the theoretical definition of the ICC?</strong></p>
<p>If you either pull two people with the same true but unobservable score <span class="math inline">\(\eta\)</span> out of the population
or measure the same person twice and the score (<span class="math inline">\(\eta\)</span>) does not change in between, we can
<strong>define reliability as correlation between these two measurements</strong>:</p>
<p><span class="math display">\[Y_1 = \eta + \varepsilon_1\]</span>
<span class="math display">\[Y_2 = \eta + \varepsilon_2\]</span></p>
<p><span class="math display">\[cor(Y_1, Y_2) = cor(\eta + \varepsilon_1, \eta + \varepsilon_2) = \frac{Cov(\eta + \varepsilon_1, \eta + \varepsilon_2)}{\sigma_{Y_1}\sigma_{Y_2}}  =\]</span></p>
<p>If we use</p>
<ul>
<li>the <a href="https://en.wikipedia.org/wiki/Covariance#Properties">properties of the covariance</a>,</li>
<li>the fact that the true score <span class="math inline">\(\eta\)</span> and the errors <span class="math inline">\(\varepsilon_i\)</span> are independent, and</li>
<li>the fact that the errors <span class="math inline">\(\varepsilon_1\)</span> and <span class="math inline">\(\varepsilon_2\)</span> are independent, we get:</li>
</ul>
<p><span class="math display">\[\frac{Cov(\eta, \eta) + Cov(\eta, \varepsilon_2) + Cov(\varepsilon_1, \eta) + Cov(\varepsilon_1, \varepsilon_2)}{\sigma_{Y_1} \sigma_{Y_2}}  =\]</span>
<span class="math display">\[\frac{\sigma_{\eta}^2 + 0 + 0 + 0}{\sigma_{Y_1} \sigma_{Y_2}}\]</span></p>
<p>Since <span class="math inline">\(\eta\)</span> is a random variable (we draw a person randomly from the population),
it is well defined to talk about the variance of <span class="math inline">\(\eta\)</span> (i.e., <span class="math inline">\(\sigma_{\eta}^2\)</span>).
I think this aspect may not come across in the book quite so clearly.</p>
<p>Furthermore, it does not matter if I call the measurement <span class="math inline">\(Y_1\)</span>, <span class="math inline">\(Y_2\)</span> or more general
<span class="math inline">\(Y\)</span>, since they have the same variance and true score:</p>
<p><span class="math display">\[\sigma_{Y} = \sigma_{Y_1} = \sigma_{Y_2}\]</span></p>
<p>Hence, it follows that:</p>
<p><span class="math display">\[cor(Y_1, Y_2) = \frac{\sigma_{\eta}^2}{\sigma_{Y_1}^2} = \frac{\sigma_{\eta}^2}{\sigma_{Y}^2} =  \frac{\sigma_{\eta}^2}{\sigma_{Y}^2} = \frac{\sigma_{\eta}^2}{\sigma_{\eta}^2 + \sigma_{\varepsilon}^2}\]</span></p>
<p>This is the <strong>intraclass correlation coefficient (ICC)</strong>.
It is (as seen in the formula above) the proportion of the
true score variability to the total variability.
It ranges from 0 and 1 (think about why!).</p>
<p>A little manipulation to improve understanding:</p>
<p>Let’s look again at the term for the ICC above and divide the numerator and the denominator by
<span class="math inline">\(\sigma_{\eta}^2\)</span>, which we can do, since it is a positive number:</p>
<p><span class="math display">\[\frac{\sigma_{\eta}^2}{\sigma_{\eta}^2 + \sigma_{\varepsilon}^2} = \frac{1}{1 + \frac{\sigma_{\varepsilon}^2}{\sigma_{\eta}^2}}\]</span></p>
<p>We could call the term <span class="math inline">\(\frac{\sigma_{\varepsilon}^2}{\sigma_{\eta}^2}\)</span> the noise-to-signal ratio.
The higher this ratio, the lower the ICC. The lower the ratio, the higher the ICC.</p>
<ul>
<li>If you increase the noise (measurement error <span class="math inline">\(\sigma_{\varepsilon}^2\)</span>) for fixed
true score variability <span class="math inline">\(\sigma_{\eta}^2\)</span>, the ICC decreases, because the denominator
increases.</li>
<li>If you increase the true score variability <span class="math inline">\(\sigma_{\eta}^2\)</span> for fixed noise <span class="math inline">\(\sigma_{\varepsilon}^2\)</span>,
the ICC increases, since the denominator decreases.</li>
</ul>
<p>Btw, we could also divide by <span class="math inline">\(\sigma_{\varepsilon}^2\)</span> and get the signal-to-noise ratio.</p>
<p>At first glance, the following statement seems wrong:</p>
<p>In a very <strong>homogeneous population</strong> (patients have very similar scores/measurements),
the <strong>ICC might be very low</strong>. The reason is that the patient variability <span class="math inline">\(\sigma_{\eta}^2\)</span> is low
and you probably have some measurement error <span class="math inline">\(\sigma_{\varepsilon}^2\)</span>.
Hence, if you look at the formula, ICC must be low (for a given measurement error).</p>
<p>On the other hand, if you have a very <strong>heterogeneous population</strong> (patients have rather different
scores/measurements), the <strong>ICC might be very high</strong>.
The reason is that the patient variability <span class="math inline">\(\sigma_{\eta}^2\)</span> is high and you probably
have some measurement error <span class="math inline">\(\sigma_{\varepsilon}^2\)</span>.</p>
<p><strong>What matters is the ratio of the two</strong>, as can be seen from the formula above.</p>
<p>Let’s try to calculate the ICC for our data using a statistical model. There are a couple of different
R packages to do this. We will use the <code>irr</code> package.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="reliability-and-validity.html#cb19-1" tabindex="-1"></a><span class="fu">library</span>(irr)</span></code></pre></div>
<pre><code>## Loading required package: lpSolve</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="reliability-and-validity.html#cb21-1" tabindex="-1"></a>irr<span class="sc">::</span><span class="fu">icc</span>(<span class="fu">as.matrix</span>(df[, <span class="fu">c</span>(<span class="st">&quot;ROMas.Peter&quot;</span>, <span class="st">&quot;ROMas.Mary&quot;</span>)]), </span>
<span id="cb21-2"><a href="reliability-and-validity.html#cb21-2" tabindex="-1"></a>    <span class="at">model =</span> <span class="st">&quot;oneway&quot;</span>, <span class="at">type =</span> <span class="st">&quot;consistency&quot;</span>)</span></code></pre></div>
<pre><code>##  Single Score Intraclass Correlation
## 
##    Model: oneway 
##    Type : consistency 
## 
##    Subjects = 50 
##      Raters = 2 
##      ICC(1) = 0.851
## 
##  F-Test, H0: r0 = 0 ; H1: r0 &gt; 0 
##    F(49,50) = 12.4 , p = 7.31e-16 
## 
##  95%-Confidence Interval for ICC Population Values:
##   0.753 &lt; ICC &lt; 0.913</code></pre>
<p>We get the result: <span class="math inline">\(ICC(1) = 0.851\)</span>, which is identical to the correlation coefficient
because there is no systematic difference between Peter and Mary.</p>
<p>Since we are forward looking and modern regression model experts,
we would like to see if we can get the result using the Bayesian
framework.</p>
<p>Below is the model structure.</p>
<p><span class="math display">\[
\begin{array}{rcl}
ROM_i &amp;\sim&amp; N(\mu_i, \sigma_{\varepsilon}) \\
\mu_i &amp;=&amp; \alpha[ID] \\
\alpha[ID] &amp;\sim&amp; \text{Normal}(\mu_{\alpha}, \sigma_{\alpha}) \\
\mu_{\alpha} &amp;\sim&amp; \text{Normal}(66, 20) \\
\sigma_{\alpha} &amp;\sim&amp; \text{Uniform}(0,20) \\
\sigma_{\varepsilon} &amp;\sim&amp; \text{Uniform}(0,20)
\end{array}
\]</span></p>
<p><strong>Model details:</strong></p>
<ul>
<li><span class="math inline">\(ROM_i\)</span> is the observed ROM-score for patient <span class="math inline">\(i\)</span>.
Every patient has two observations (one each from Mary and Peter).
So, for instance <span class="math inline">\(i=1,2\)</span> could be patient <span class="math inline">\(ID=1\)</span>.</li>
<li><span class="math inline">\(\mu_i\)</span> is the expected value of the observed score for patient <span class="math inline">\(ID\)</span>.</li>
<li><span class="math inline">\(\sigma_{\varepsilon}\)</span> is the standard deviation of the measurement error.</li>
<li><span class="math inline">\(\alpha[ID]\)</span> is the patient-specific intercept (<span class="math inline">\(=\eta_i\)</span>).
Since every patient has a different intercept and they
come from a normal distribution, we have a <strong>random intercepts model</strong>.</li>
<li><span class="math inline">\(\mu_{\alpha}\)</span> is the mean of the prior for the patient-specific intercepts.
This is the overall mean of the scores.</li>
<li><span class="math inline">\(\sigma_{\alpha}\)</span> is the standard deviation of the patient-specific intercepts.
<strong>This is the patient variability</strong>! The nice thing about presenting a model in this
way is that it’s easier to interpret. <span class="math inline">\(\sigma_{\alpha}\)</span> says how much
the scores of the patients vary in relation to their respective level <span class="math inline">\(\alpha[ID]\)</span>.</li>
<li>The prior distributions express (as always) our prior beliefs about the parameters.</li>
</ul>
<p>The <strong>ICC</strong> is then calculated as the ratio of the between-patient variance and
the total variance:</p>
<p><span class="math display">\[\frac{\sigma_{\alpha}^2}{\sigma_{\alpha}^2 + \sigma_{\varepsilon}^2}\]</span></p>
<p>We did not even notice it, but this was our first <strong>multilevel regression model</strong>.
It is multilevel due to the extra layer of patient-specific intercepts.
The <strong>observations</strong> are obviously <strong>clustered within patients</strong>, since observations
from the <strong>same patient</strong> are <strong>more similar than observations from different patients</strong>.
If one would run a normal linear regression model, one would ignore this clustering
and the assumption of independent error terms would be violated.</p>
<p>Draw model structure … exercise..</p>
<p>This time we fire up the <code>rethinking</code> package and use the <code>ulam</code> function
to fit the model.
This uses Markov Chain Monte Carlo (MCMC) to sample from the posterior
distribution of the parameters.</p>
<ul>
<li><p>The <code>chains</code> argument specifies how many chains we want to run.
A <em>chain</em> is a sequence of points in a space with as many dimensions as there
are parameters in the model. It jumps from one point to the next in this parameter
space and in doing so, visits the points of the posterior approximately in the correct
frequency. <a href="https://blog.revolutionanalytics.com/2013/09/an-animated-peek-into-the-workings-of-bayesian-statistics.html">Here</a>
is an excellent visualization.</p></li>
<li><p>The <code>cores</code> argument specifies how many CPU cores we want to use.
For larger jobs, one can try to parallelize
the chains, which saves some time.</p></li>
</ul>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="reliability-and-validity.html#cb23-1" tabindex="-1"></a><span class="fu">library</span>(rethinking)</span></code></pre></div>
<pre><code>## Loading required package: cmdstanr</code></pre>
<pre><code>## This is cmdstanr version 0.8.1.9000</code></pre>
<pre><code>## - CmdStanR documentation and vignettes: mc-stan.org/cmdstanr</code></pre>
<pre><code>## - CmdStan path: /Users/juergen/.cmdstan/cmdstan-2.34.1</code></pre>
<pre><code>## - CmdStan version: 2.34.1</code></pre>
<pre><code>## 
## A newer version of CmdStan is available. See ?install_cmdstan() to install it.
## To disable this check set option or environment variable cmdstanr_no_ver_check=TRUE.</code></pre>
<pre><code>## Loading required package: posterior</code></pre>
<pre><code>## This is posterior version 1.6.0</code></pre>
<pre><code>## 
## Attaching package: &#39;posterior&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     mad, sd, var</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     %in%, match</code></pre>
<pre><code>## Loading required package: parallel</code></pre>
<pre><code>## rethinking (Version 2.42)</code></pre>
<pre><code>## 
## Attaching package: &#39;rethinking&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     map</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     rstudent</code></pre>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="reliability-and-validity.html#cb40-1" tabindex="-1"></a><span class="fu">library</span>(tictoc)</span>
<span id="cb40-2"><a href="reliability-and-validity.html#cb40-2" tabindex="-1"></a></span>
<span id="cb40-3"><a href="reliability-and-validity.html#cb40-3" tabindex="-1"></a>df_long <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> </span>
<span id="cb40-4"><a href="reliability-and-validity.html#cb40-4" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ID =</span> <span class="fu">row_number</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb40-5"><a href="reliability-and-validity.html#cb40-5" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(ID,ROMas.Peter, ROMas.Mary) <span class="sc">%&gt;%</span> </span>
<span id="cb40-6"><a href="reliability-and-validity.html#cb40-6" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">c</span>(ROMas.Peter, ROMas.Mary), </span>
<span id="cb40-7"><a href="reliability-and-validity.html#cb40-7" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">&quot;Rater&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;ROM&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb40-8"><a href="reliability-and-validity.html#cb40-8" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Rater =</span> <span class="fu">factor</span>(Rater))</span>
<span id="cb40-9"><a href="reliability-and-validity.html#cb40-9" tabindex="-1"></a></span>
<span id="cb40-10"><a href="reliability-and-validity.html#cb40-10" tabindex="-1"></a><span class="fu">tic</span>()</span>
<span id="cb40-11"><a href="reliability-and-validity.html#cb40-11" tabindex="-1"></a>m5<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb40-12"><a href="reliability-and-validity.html#cb40-12" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb40-13"><a href="reliability-and-validity.html#cb40-13" tabindex="-1"></a>    <span class="co"># Likelihood</span></span>
<span id="cb40-14"><a href="reliability-and-validity.html#cb40-14" tabindex="-1"></a>    ROM <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb40-15"><a href="reliability-and-validity.html#cb40-15" tabindex="-1"></a>    </span>
<span id="cb40-16"><a href="reliability-and-validity.html#cb40-16" tabindex="-1"></a>    <span class="co"># Patient-specific intercepts (random effects)</span></span>
<span id="cb40-17"><a href="reliability-and-validity.html#cb40-17" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a[ID],  </span>
<span id="cb40-18"><a href="reliability-and-validity.html#cb40-18" tabindex="-1"></a>    a[ID] <span class="sc">~</span> <span class="fu">dnorm</span>(mu_a, sigma_ID),  <span class="co"># Hierarchical structure for patients</span></span>
<span id="cb40-19"><a href="reliability-and-validity.html#cb40-19" tabindex="-1"></a>    </span>
<span id="cb40-20"><a href="reliability-and-validity.html#cb40-20" tabindex="-1"></a>    <span class="co"># Priors for hyperparameters</span></span>
<span id="cb40-21"><a href="reliability-and-validity.html#cb40-21" tabindex="-1"></a>    mu_a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">66</span>, <span class="dv">20</span>),  <span class="co"># Population-level mean</span></span>
<span id="cb40-22"><a href="reliability-and-validity.html#cb40-22" tabindex="-1"></a>    sigma_ID <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">20</span>),  <span class="co"># Between-patient standard deviation</span></span>
<span id="cb40-23"><a href="reliability-and-validity.html#cb40-23" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">20</span>)  <span class="co"># Residual standard deviation</span></span>
<span id="cb40-24"><a href="reliability-and-validity.html#cb40-24" tabindex="-1"></a>  ), </span>
<span id="cb40-25"><a href="reliability-and-validity.html#cb40-25" tabindex="-1"></a>  <span class="at">data =</span> df_long, </span>
<span id="cb40-26"><a href="reliability-and-validity.html#cb40-26" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">8</span>, <span class="at">cores =</span> <span class="dv">4</span></span>
<span id="cb40-27"><a href="reliability-and-validity.html#cb40-27" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Running MCMC with 8 chains, at most 4 in parallel, with 1 thread(s) per chain...
## 
## Chain 1 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 1 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 1 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 1 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 1 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 1 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 1 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 1 Iteration: 1000 / 1000 [100%]  (Sampling)</code></pre>
<pre><code>## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 1 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmpugyJzF/model-4094303b9fbc.stan&#39;, line 17, column 4 to column 34)</code></pre>
<pre><code>## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 1</code></pre>
<pre><code>## Chain 2 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 2 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 2 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 2 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 2 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 2 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 2 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 2 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 2 Iteration: 700 / 1000 [ 70%]  (Sampling)</code></pre>
<pre><code>## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 2 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmpugyJzF/model-4094303b9fbc.stan&#39;, line 17, column 4 to column 34)</code></pre>
<pre><code>## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 2</code></pre>
<pre><code>## Chain 3 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 3 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 3 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 3 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 3 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 3 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 3 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 3 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 3 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 3 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 3 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 3 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 4 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 4 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 4 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 4 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 4 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 4 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 4 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 4 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 4 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 4 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 4 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 4 Iteration: 1000 / 1000 [100%]  (Sampling)</code></pre>
<pre><code>## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 4 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmpugyJzF/model-4094303b9fbc.stan&#39;, line 17, column 4 to column 34)</code></pre>
<pre><code>## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 4</code></pre>
<pre><code>## Chain 1 finished in 0.1 seconds.
## Chain 3 finished in 0.1 seconds.
## Chain 4 finished in 0.1 seconds.
## Chain 2 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 2 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 2 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 5 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 5 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 5 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 5 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 5 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 5 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 5 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 5 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 5 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 5 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 5 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 5 Iteration: 1000 / 1000 [100%]  (Sampling)</code></pre>
<pre><code>## Chain 5 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 5 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmpugyJzF/model-4094303b9fbc.stan&#39;, line 17, column 4 to column 34)</code></pre>
<pre><code>## Chain 5 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 5 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 5</code></pre>
<pre><code>## Chain 6 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 6 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 6 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 6 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 6 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 6 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 6 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 6 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 6 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 6 Iteration: 800 / 1000 [ 80%]  (Sampling)</code></pre>
<pre><code>## Chain 6 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 6 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmpugyJzF/model-4094303b9fbc.stan&#39;, line 17, column 4 to column 34)</code></pre>
<pre><code>## Chain 6 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 6 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 6</code></pre>
<pre><code>## Chain 7 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 7 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 7 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 7 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 7 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 7 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 7 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 7 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 7 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 7 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 7 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 7 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 2 finished in 0.2 seconds.
## Chain 5 finished in 0.1 seconds.
## Chain 6 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 6 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 6 finished in 0.1 seconds.
## Chain 7 finished in 0.1 seconds.
## Chain 8 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 8 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 8 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 8 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 8 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 8 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 8 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 8 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 8 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 8 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 8 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 8 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 8 finished in 0.1 seconds.
## 
## All 8 chains finished successfully.
## Mean chain execution time: 0.1 seconds.
## Total execution time: 0.6 seconds.</code></pre>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="reliability-and-validity.html#cb72-1" tabindex="-1"></a><span class="fu">toc</span>() <span class="co"># 7s</span></span></code></pre></div>
<pre><code>## 6.582 sec elapsed</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="reliability-and-validity.html#cb74-1" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.1</span>, <span class="at">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##               mean        sd      5.5%     94.5%      rhat ess_bulk
## a[1]     67.722244 4.9090800 59.884240 75.424230 1.0011883 6619.262
## a[2]     64.111654 4.7840605 56.528447 71.776798 1.0034783 6191.276
## a[3]     86.987105 4.8248501 79.310842 94.721499 1.0021836 6533.691
## a[4]     76.488312 4.8772869 68.688592 84.377506 1.0004241 6088.506
## a[5]     58.652587 4.9146668 50.800481 66.376233 1.0057245 6894.371
## a[6]     69.286318 4.9001887 61.446915 77.135439 1.0023860 6440.228
## a[7]     69.630175 4.7214488 62.093989 77.274188 1.0042853 6102.224
## a[8]     67.364715 4.8073624 59.760551 74.940179 1.0004233 6926.255
## a[9]     70.982913 4.8029119 63.473921 78.838160 1.0021779 6096.437
## a[10]    81.123297 4.6829024 73.463408 88.601603 1.0000833 5882.855
## a[11]    70.525946 4.7789205 62.916758 78.015190 1.0027020 6057.395
## a[12]    42.158971 4.9255574 34.330380 50.142874 1.0052952 5608.430
## a[13]    86.981146 4.8049263 79.173926 94.829309 1.0006401 5697.280
## a[14]    74.665706 4.6060512 67.261235 81.970150 1.0042568 6217.659
## a[15]    76.383198 4.8629608 68.375808 84.099854 1.0019507 5393.146
## a[16]    34.941636 4.9924846 27.056167 43.018477 1.0015714 6091.685
## a[17]    84.803446 4.7374711 77.144124 92.406944 0.9993908 4742.513
## a[18]    64.997487 4.9643186 56.943773 72.939016 1.0035173 6046.231
## a[19]    63.285164 4.9025730 55.533948 71.178041 1.0013061 5093.825
## a[20]    79.685208 5.0087033 71.658232 87.571054 1.0025818 5732.622
## a[21]    30.284397 4.9534314 22.471539 38.175759 1.0029669 4993.642
## a[22]    62.717165 4.8429270 55.056809 70.508550 1.0042888 5186.047
## a[23]    67.369138 4.7935870 59.691637 75.021504 1.0015468 5712.044
## a[24]    81.364895 4.6500222 73.951702 88.744605 1.0010820 5840.154
## a[25]    54.960936 4.6723859 47.304353 62.472893 1.0031483 6486.986
## a[26]    67.484558 4.8629666 59.694329 75.237344 1.0024718 5631.800
## a[27]    75.662864 4.6822039 68.289372 83.149005 1.0015293 5142.724
## a[28]    81.458669 4.7261292 73.931357 89.044628 1.0007963 6429.453
## a[29]    46.319123 4.9454046 38.515295 54.285881 1.0011816 5884.281
## a[30]    61.257367 4.7772157 53.562560 68.978274 1.0023302 5689.914
## a[31]    23.509215 4.9033830 15.777376 31.510781 1.0033955 4020.937
## a[32]    74.135907 4.9851734 66.120570 81.958539 1.0022234 6227.534
## a[33]    70.503386 4.7654367 62.891725 78.072130 1.0023102 5314.875
## a[34]    76.514259 4.7673813 69.060676 84.004384 1.0056486 6295.756
## a[35]    75.552330 4.7650873 68.063417 83.238239 1.0059815 6458.817
## a[36]    69.318470 4.8028313 61.733604 76.842796 1.0019923 5624.692
## a[37]    49.567778 4.8517137 42.000534 57.348616 1.0001428 5345.948
## a[38]    73.807516 4.8704217 66.012632 81.610347 1.0014698 5593.351
## a[39]    72.757513 4.8058223 65.331446 80.543411 0.9996477 6046.893
## a[40]    45.817525 4.8801249 38.090789 53.659197 1.0017618 5810.945
## a[41]    73.683223 4.8798317 65.754844 81.586076 0.9997154 5788.226
## a[42]    26.096569 5.0020037 18.151000 34.085055 1.0035820 5645.769
## a[43]    32.929828 4.9839276 25.060965 40.934064 1.0009925 4969.622
## a[44]    74.142579 4.8767249 66.482373 81.844996 1.0027673 5518.837
## a[45]    76.914062 4.8315152 69.190795 84.479135 1.0021492 5799.564
## a[46]    73.639372 4.7714194 66.006190 81.297628 1.0014867 5772.895
## a[47]    55.859204 4.8616217 48.241338 63.875677 1.0018038 5633.257
## a[48]    69.603460 4.7802544 61.990560 77.160122 1.0024286 5065.542
## a[49]    72.402414 4.6825454 65.012180 79.784921 1.0015697 5911.021
## a[50]    72.770000 4.8603442 65.014248 80.455220 1.0029222 7919.236
## mu_a     65.555333 2.4626739 61.598423 69.494927 1.0017301 4186.431
## sigma_ID 16.613184 1.6346644 14.010696 19.244560 1.0024463 1915.575
## sigma     7.081393 0.7331837  6.011486  8.331337 1.0004015 2066.538</code></pre>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="reliability-and-validity.html#cb76-1" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m5<span class="fl">.1</span>)</span>
<span id="cb76-2"><a href="reliability-and-validity.html#cb76-2" tabindex="-1"></a>var_patients <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>sigma_ID<span class="sc">^</span><span class="dv">2</span>)  <span class="co"># Between-patient variance</span></span>
<span id="cb76-3"><a href="reliability-and-validity.html#cb76-3" tabindex="-1"></a>var_residual <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span>)     <span class="co"># Residual variance</span></span>
<span id="cb76-4"><a href="reliability-and-validity.html#cb76-4" tabindex="-1"></a>var_patients <span class="sc">/</span> (var_patients <span class="sc">+</span> var_residual) <span class="co"># ICC</span></span></code></pre></div>
<pre><code>## [1] 0.8461117</code></pre>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="reliability-and-validity.html#cb78-1" tabindex="-1"></a><span class="co"># 0.846</span></span>
<span id="cb78-2"><a href="reliability-and-validity.html#cb78-2" tabindex="-1"></a><span class="co"># not too bad; very close to the result from the irr package</span></span></code></pre></div>
<p>In the output from <code>precis(m5.1, depth = 2)</code> above we see</p>
<ul>
<li>all 50 intercept estimates for each patient: <code>a[ID]</code></li>
<li><code>mu_a</code>is the overall intercept.</li>
<li><code>sigma_ID</code> is the <strong>patient variability</strong>.</li>
<li><code>sigma</code> is the <strong>residual variability</strong>.</li>
</ul>
<p>We just square the sigmas to get the variances.</p>
<p>Remember: In the background, there is just a statistical model to predict
the outcome. Depending on the predictors, we get different models and
probably different ICCs.</p>
<p>We can also estimate a <strong>random intercept model</strong> with the <code>lme4</code> package using
the command <code>lmer</code>in the Frequentist framework. No priors.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="reliability-and-validity.html#cb79-1" tabindex="-1"></a><span class="fu">library</span>(lme4)</span></code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:tidyr&#39;:
## 
##     expand, pack, unpack</code></pre>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="reliability-and-validity.html#cb83-1" tabindex="-1"></a>m5<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lmer</span>(ROM <span class="sc">~</span> (<span class="dv">1</span><span class="sc">|</span>ID), <span class="at">data =</span> df_long)</span>
<span id="cb83-2"><a href="reliability-and-validity.html#cb83-2" tabindex="-1"></a><span class="fu">summary</span>(m5<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: ROM ~ (1 | ID)
##    Data: df_long
## 
## REML criterion at convergence: 791
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.91875 -0.44821  0.00964  0.51325  1.47941 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  ID       (Intercept) 270.99   16.462  
##  Residual              47.35    6.881  
## Number of obs: 100, groups:  ID, 50
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)   65.590      2.428   27.02</code></pre>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="reliability-and-validity.html#cb85-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">VarCorr</span>(m5<span class="fl">.2</span>), <span class="at">comp =</span> <span class="st">&quot;Variance&quot;</span>)</span></code></pre></div>
<pre><code>##  Groups   Name        Variance
##  ID       (Intercept) 270.99  
##  Residual              47.35</code></pre>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="reliability-and-validity.html#cb87-1" tabindex="-1"></a><span class="co"># ICC = </span></span>
<span id="cb87-2"><a href="reliability-and-validity.html#cb87-2" tabindex="-1"></a><span class="fl">270.99</span> <span class="sc">/</span> (<span class="fl">270.99</span> <span class="sc">+</span> <span class="fl">47.35</span>) <span class="co"># </span></span></code></pre></div>
<pre><code>## [1] 0.8512597</code></pre>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="reliability-and-validity.html#cb89-1" tabindex="-1"></a><span class="co"># 0.8512597</span></span>
<span id="cb89-2"><a href="reliability-and-validity.html#cb89-2" tabindex="-1"></a><span class="co"># -&gt; exactly the same result as the irr package</span></span></code></pre></div>
<p>The expression <code>Formula: ROM ~ (1 | ID)</code> specifies that we want to fit a model with
a random intercept. This means that every patient (ID) gets its own intercept
which is drawn from a normal distribution. We will probably talk about this in the
next lecture (Methodenvertiefung) in greater detail.</p>
<p>So far, we have only looked at the general <strong><span class="math inline">\(ICC\)</span></strong> (ICC1 in the <code>psych</code>output)
(see also page 106 in the book).</p>
<p>There, we have not yet explicitely considered a bias (=systematic difference
between the raters) that the raters could have. In the book,
they introduce a bias of 5 degrees (Mary measures 5 degrees more than Peter on average).</p>
<p>The model für ICC 2 and 3 in the <code>psych</code> output explicitely considers this
(systematic) difference that could occur between the raters.
This results in an extra term in the denominator
of the ICC, an additional variance component.</p>
<p>From the same statistical model (!) we take the variance components to calculate:</p>
<p><span class="math display">\[ICC_{agreement} = \frac{\sigma_{\alpha}^2}{\sigma_{\alpha}^2 + \mathbf{\sigma_{rater}^2} + \sigma_{\varepsilon}^2}\]</span></p>
<p>where <span class="math inline">\(\sigma_{rater}^2\)</span> is the variance due to systematic rater differences.</p>
<p><span class="math display">\[ICC_{consistency} = \frac{\sigma_{\alpha}^2}{\sigma_{\alpha}^2 + \sigma_{\varepsilon}^2}\]</span></p>
<p>We will now introduce the 5 degree bias and use our Bayesian
framework to estimate the ICC.
By introducing a bias, we should see
a lower ICC. Note, that the prediction quality of Mary’s scores
given Peter’s scores should not change, since we would only shift Mary’s scores
down by 5 degrees, which would not disturb the linear regression model. We can
always shift the points to where we want them to be. We do that for instance
when we scale or standardize the data.</p>
<p>Admitted, the Bayesian version in this case takes longer and is more complex.
The advantage is still that it’s fully probabilistic and one could work with
detailed prior information, especially for smaller smaple sizes.</p>
<p>Anyhow, let’s try to give the model equations considering
the introduced bias. This is the model for both
<span class="math inline">\(ICC_{agreement}\)</span> and <span class="math inline">\(ICC_{consistency}\)</span>!</p>
<p><span class="math display">\[
\begin{array}{rcl}
ROM_i &amp;\sim&amp; N(\mu_i, \sigma_{\varepsilon}) \\
\mu_i &amp;=&amp; \alpha[ID] + \beta[Rater] \\
\alpha[ID] &amp;\sim&amp; \text{Normal}(\mu_{\alpha}, \sigma_{\alpha}) \\
\beta[Rater] &amp;\sim&amp; \text{Normal}(0, \sigma_{\beta}) \\
\mu_{\alpha} &amp;\sim&amp; \text{Normal}(66, 20) \\
\sigma_{\alpha} &amp;\sim&amp; \text{Exp}(0.5) \\
\sigma_{\beta} &amp;\sim&amp; \text{Exp}(1) \\
\sigma_{\varepsilon} &amp;\sim&amp; \text{Exp}(1)
\end{array}
\]</span></p>
<p>As you can see, <span class="math inline">\(\mu_i\)</span> now consists of the patient-specific intercept <span class="math inline">\(\alpha[ID]\)</span>
(everyone of the 50 patients gets one)
and the rater-specific effect <span class="math inline">\(\beta[Rater]\)</span> (Mary and Peter get one).
So, in total, we have <strong>three sources of variability</strong>:</p>
<ul>
<li>the patient variability <span class="math inline">\(\sigma_{\alpha}\)</span>,</li>
<li>the rater variability <span class="math inline">\(\sigma_{\beta}\)</span>,</li>
<li>and the residual variability <span class="math inline">\(\sigma_{\varepsilon}\)</span>.</li>
</ul>
<p>Note, that if Peter measures each of the 50 patients twice,
the systematic difference between Peter’s measurements would
be zero. Of course, one could be creative and think of
a learning effect or something.</p>
<p>Draw model structure … exercise..</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="reliability-and-validity.html#cb90-1" tabindex="-1"></a><span class="fu">library</span>(rethinking)</span>
<span id="cb90-2"><a href="reliability-and-validity.html#cb90-2" tabindex="-1"></a><span class="fu">library</span>(conflicted)</span>
<span id="cb90-3"><a href="reliability-and-validity.html#cb90-3" tabindex="-1"></a><span class="fu">conflicts_prefer</span>(posterior<span class="sc">::</span>sd)</span></code></pre></div>
<pre><code>## [conflicted] Will prefer posterior::sd over any other package.</code></pre>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="reliability-and-validity.html#cb92-1" tabindex="-1"></a>df_long_bias <span class="ot">&lt;-</span> df_long <span class="sc">%&gt;%</span></span>
<span id="cb92-2"><a href="reliability-and-validity.html#cb92-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ROM =</span> ROM <span class="sc">+</span> <span class="fu">ifelse</span>(Rater <span class="sc">==</span> <span class="st">&quot;ROMas.Mary&quot;</span>, <span class="dv">5</span>, <span class="dv">0</span>))</span>
<span id="cb92-3"><a href="reliability-and-validity.html#cb92-3" tabindex="-1"></a><span class="fu">head</span>(df_long_bias)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 3
##      ID Rater         ROM
##   &lt;int&gt; &lt;fct&gt;       &lt;dbl&gt;
## 1     1 ROMas.Peter    66
## 2     1 ROMas.Mary     75
## 3     2 ROMas.Peter    65
## 4     2 ROMas.Mary     68
## 5     3 ROMas.Peter    96
## 6     3 ROMas.Mary     87</code></pre>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="reliability-and-validity.html#cb94-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb94-2"><a href="reliability-and-validity.html#cb94-2" tabindex="-1"></a>m5<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb94-3"><a href="reliability-and-validity.html#cb94-3" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb94-4"><a href="reliability-and-validity.html#cb94-4" tabindex="-1"></a>    <span class="co"># Likelihood</span></span>
<span id="cb94-5"><a href="reliability-and-validity.html#cb94-5" tabindex="-1"></a>    ROM <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma_eps),</span>
<span id="cb94-6"><a href="reliability-and-validity.html#cb94-6" tabindex="-1"></a>    </span>
<span id="cb94-7"><a href="reliability-and-validity.html#cb94-7" tabindex="-1"></a>    <span class="co"># Model for mean ROM with patient and rater effects</span></span>
<span id="cb94-8"><a href="reliability-and-validity.html#cb94-8" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> alpha[ID] <span class="sc">+</span> beta[Rater],</span>
<span id="cb94-9"><a href="reliability-and-validity.html#cb94-9" tabindex="-1"></a>    </span>
<span id="cb94-10"><a href="reliability-and-validity.html#cb94-10" tabindex="-1"></a>    <span class="co"># Patient-specific random effects</span></span>
<span id="cb94-11"><a href="reliability-and-validity.html#cb94-11" tabindex="-1"></a>    alpha[ID] <span class="sc">~</span> <span class="fu">dnorm</span>(mu_alpha, sigma_alpha),</span>
<span id="cb94-12"><a href="reliability-and-validity.html#cb94-12" tabindex="-1"></a>    </span>
<span id="cb94-13"><a href="reliability-and-validity.html#cb94-13" tabindex="-1"></a>    <span class="co"># Rater effect (Peter/Mary)</span></span>
<span id="cb94-14"><a href="reliability-and-validity.html#cb94-14" tabindex="-1"></a>    beta[Rater] <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, sigma_beta),</span>
<span id="cb94-15"><a href="reliability-and-validity.html#cb94-15" tabindex="-1"></a>    </span>
<span id="cb94-16"><a href="reliability-and-validity.html#cb94-16" tabindex="-1"></a>    <span class="co"># Priors for hyperparameters</span></span>
<span id="cb94-17"><a href="reliability-and-validity.html#cb94-17" tabindex="-1"></a>    mu_alpha <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">66</span>, <span class="dv">10</span>),  <span class="co"># Population mean ROM</span></span>
<span id="cb94-18"><a href="reliability-and-validity.html#cb94-18" tabindex="-1"></a>    sigma_alpha <span class="sc">~</span> <span class="fu">dexp</span>(<span class="fl">0.5</span>),  <span class="co"># Between-patient SD (less aggressive shrinkage)</span></span>
<span id="cb94-19"><a href="reliability-and-validity.html#cb94-19" tabindex="-1"></a>    sigma_beta <span class="sc">~</span> <span class="fu">dexp</span>(<span class="dv">1</span>),   <span class="co"># Rater SD (better regularization)</span></span>
<span id="cb94-20"><a href="reliability-and-validity.html#cb94-20" tabindex="-1"></a>    sigma_eps <span class="sc">~</span> <span class="fu">dexp</span>(<span class="dv">1</span>)     <span class="co"># Residual SD (prevents over-shrinkage)</span></span>
<span id="cb94-21"><a href="reliability-and-validity.html#cb94-21" tabindex="-1"></a>  ), </span>
<span id="cb94-22"><a href="reliability-and-validity.html#cb94-22" tabindex="-1"></a>  <span class="at">data =</span> df_long_bias, </span>
<span id="cb94-23"><a href="reliability-and-validity.html#cb94-23" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">8</span>, <span class="at">cores =</span> <span class="dv">4</span></span>
<span id="cb94-24"><a href="reliability-and-validity.html#cb94-24" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Running MCMC with 8 chains, at most 4 in parallel, with 1 thread(s) per chain...
## 
## Chain 1 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 1 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 1 Iteration: 200 / 1000 [ 20%]  (Warmup)</code></pre>
<pre><code>## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:
## Chain 1 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmpugyJzF/model-40946483280.stan&#39;, line 21, column 4 to column 45)
## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,
## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.
## Chain 1</code></pre>
<pre><code>## Chain 2 Iteration:   1 / 1000 [  0%]  (Warmup)</code></pre>
<pre><code>## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:
## Chain 2 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmpugyJzF/model-40946483280.stan&#39;, line 21, column 4 to column 45)
## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,
## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.
## Chain 2</code></pre>
<pre><code>## Chain 3 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 3 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 4 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 4 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 4 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 4 Iteration: 300 / 1000 [ 30%]  (Warmup)</code></pre>
<pre><code>## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:
## Chain 4 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmpugyJzF/model-40946483280.stan&#39;, line 21, column 4 to column 45)
## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,
## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.
## Chain 4</code></pre>
<pre><code>## Chain 1 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 1 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 1 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 1 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 1 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 2 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 2 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 2 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 2 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 2 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 2 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 2 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 2 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 2 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 2 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 3 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 3 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 3 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 3 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 3 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 3 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 3 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 3 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 3 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 3 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 4 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 4 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 4 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 4 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 4 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 4 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 4 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 4 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 1 finished in 0.2 seconds.
## Chain 3 finished in 0.2 seconds.
## Chain 4 finished in 0.2 seconds.
## Chain 2 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 5 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 5 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 5 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 5 Iteration: 300 / 1000 [ 30%]  (Warmup)</code></pre>
<pre><code>## Chain 5 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:
## Chain 5 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmpugyJzF/model-40946483280.stan&#39;, line 21, column 4 to column 45)
## Chain 5 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,
## Chain 5 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.
## Chain 5</code></pre>
<pre><code>## Chain 6 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 6 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 6 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 6 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 7 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 7 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 7 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 7 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 7 Iteration: 400 / 1000 [ 40%]  (Warmup)</code></pre>
<pre><code>## Chain 7 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:
## Chain 7 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmpugyJzF/model-40946483280.stan&#39;, line 21, column 4 to column 45)
## Chain 7 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,
## Chain 7 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.
## Chain 7</code></pre>
<pre><code>## Chain 2 finished in 0.3 seconds.
## Chain 5 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 5 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 5 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 5 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 5 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 5 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 5 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 5 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 6 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 6 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 6 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 6 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 6 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 6 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 6 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 6 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 7 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 7 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 7 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 7 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 7 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 7 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 7 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 8 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 5 finished in 0.2 seconds.
## Chain 6 finished in 0.2 seconds.
## Chain 7 finished in 0.2 seconds.
## Chain 8 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 8 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 8 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 8 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 8 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 8 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 8 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 8 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 8 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 8 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 8 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 8 finished in 0.2 seconds.
## 
## All 8 chains finished successfully.
## Mean chain execution time: 0.2 seconds.
## Total execution time: 0.8 seconds.</code></pre>
<pre><code>## Warning: 27 of 4000 (1.0%) transitions ended with a divergence.
## See https://mc-stan.org/misc/warnings for details.</code></pre>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="reliability-and-validity.html#cb107-1" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.2</span>, <span class="at">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##                  mean        sd       5.5%      94.5%     rhat  ess_bulk
## alpha[1]    70.221230 4.6957078 62.9122250 77.6751330 1.003921 3956.8010
## alpha[2]    66.637192 4.7935979 59.2921655 74.3219425 1.000703 4048.1323
## alpha[3]    89.391211 4.8460529 81.8305935 96.9301420 1.001484 3581.3337
## alpha[4]    79.068129 4.7090695 71.7267400 86.7491720 1.002625 4088.4617
## alpha[5]    61.248545 4.6824417 53.8962900 68.7503010 1.002206 3886.9310
## alpha[6]    71.711300 4.5314894 64.4525160 79.0005630 1.001403 3806.2065
## alpha[7]    72.121798 4.7349544 64.6055805 79.6941110 1.001856 3482.5502
## alpha[8]    69.834714 4.7037178 62.3043635 77.3545565 1.000583 4054.8858
## alpha[9]    73.526363 4.7369985 66.0854635 81.0876520 1.001352 3708.7551
## alpha[10]   83.497318 4.7172575 76.0272720 91.0849000 1.001394 3871.4522
## alpha[11]   73.114282 4.6041905 65.8139360 80.4195110 1.002261 3330.7789
## alpha[12]   44.827995 4.8132889 37.2627160 52.4649335 1.003939 3774.3717
## alpha[13]   89.401919 4.7509654 81.8033940 96.8927025 1.001166 3733.9925
## alpha[14]   77.155674 4.7663782 69.3451470 84.8327385 1.002594 3611.6344
## alpha[15]   78.928227 4.8283770 71.2416295 86.6386025 1.005149 3462.8282
## alpha[16]   37.537016 4.8929538 29.6438890 45.4816100 1.000967 3802.3178
## alpha[17]   87.205983 4.6947001 79.8024680 94.7725850 1.004141 3205.6678
## alpha[18]   67.618180 4.6490608 60.4495525 74.8906485 1.000691 3565.7257
## alpha[19]   65.734938 4.7038246 58.2243970 73.1307710 1.003272 3021.3632
## alpha[20]   82.148125 4.6634709 74.8132215 89.4844660 1.001809 3525.2622
## alpha[21]   32.959556 4.7365812 25.6872720 40.6902550 1.000230 3896.3144
## alpha[22]   65.312545 4.7691775 57.6339360 72.9769385 1.001701 3888.3018
## alpha[23]   69.922455 4.6557324 62.4829305 77.3353785 1.004454 3949.3830
## alpha[24]   84.028041 4.8666565 76.4453060 91.8557125 1.002520 4582.8271
## alpha[25]   57.576782 4.6027933 50.1384940 65.0507070 1.003696 3883.0937
## alpha[26]   69.844403 4.5423390 62.4724325 77.0730070 1.002214 3588.0981
## alpha[27]   78.181829 4.6438020 70.9217780 85.6579100 1.000977 3573.7990
## alpha[28]   83.976099 4.7519956 76.3497625 91.4832750 1.000891 3836.6036
## alpha[29]   48.888864 4.6981990 41.3078680 56.4819905 1.001334 4153.8714
## alpha[30]   63.812328 4.7111640 56.4071725 71.2587825 1.003047 3935.6824
## alpha[31]   26.098770 4.8818137 18.3637725 33.9304330 1.003445 4068.8549
## alpha[32]   76.676408 4.7365322 69.0211035 83.9915570 1.002364 3823.5694
## alpha[33]   73.055353 4.6273537 65.9705020 80.5753430 1.002063 4039.5757
## alpha[34]   78.963166 4.7676436 71.3900570 86.3736705 1.001748 3403.3517
## alpha[35]   78.075230 4.7744829 70.5443095 85.7926805 1.001281 4222.4407
## alpha[36]   71.652651 4.7601329 64.0808175 79.2662110 1.000708 4471.9540
## alpha[37]   52.084764 4.7084537 44.8942315 59.7080135 1.002348 3439.9837
## alpha[38]   76.121385 4.8822293 68.3599335 83.7502705 1.002290 4006.6888
## alpha[39]   75.451394 4.7905587 67.7880930 82.8390550 1.000887 3454.6782
## alpha[40]   48.408307 4.7026185 40.9218930 56.1687365 1.003060 3999.9664
## alpha[41]   76.176540 4.6262898 68.7745580 83.5991630 1.004537 3963.8804
## alpha[42]   28.812970 4.7775508 21.1928615 36.4243750 1.003746 3855.7962
## alpha[43]   35.646945 4.6876761 28.1427865 43.0427785 1.000564 4114.5370
## alpha[44]   76.736915 4.6819911 69.0549725 83.9337520 1.003016 3594.7244
## alpha[45]   79.377066 4.6099939 71.8918425 86.7122600 1.001080 4016.1217
## alpha[46]   76.266121 4.6936374 68.9066090 83.8324250 1.000442 4007.8677
## alpha[47]   58.467633 4.5906174 51.1480830 65.6998370 1.002588 3396.4658
## alpha[48]   72.114214 4.7995591 64.4240875 79.7356615 1.005283 3715.8719
## alpha[49]   74.771082 4.6137731 67.3251525 82.0455495 1.001963 3457.0385
## alpha[50]   75.414102 4.7692631 67.7589025 83.1030340 1.001202 4211.2151
## beta[1]      1.196482 1.4699703 -0.7591575  3.6725132 1.005792  932.0193
## beta[2]     -1.260339 1.5058841 -3.8538230  0.6600649 1.007244  857.8581
## mu_alpha    67.979401 2.5706977 63.9069175 72.0885400 1.003032 1842.7425
## sigma_alpha 15.457249 1.6142987 13.1380645 18.2104485 1.000383 4277.2078
## sigma_beta   1.685571 1.0527940  0.3547305  3.5587972 1.001191 1581.1771
## sigma_eps    6.713486 0.6434269  5.7619659  7.7933864 1.004713 2175.7641</code></pre>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="reliability-and-validity.html#cb109-1" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 52 vector or matrix parameters hidden. Use depth=2 to show them.</code></pre>
<pre><code>##                  mean        sd       5.5%     94.5%     rhat ess_bulk
## mu_alpha    67.979401 2.5706977 63.9069175 72.088540 1.003032 1842.742
## sigma_alpha 15.457249 1.6142987 13.1380645 18.210449 1.000383 4277.208
## sigma_beta   1.685571 1.0527940  0.3547305  3.558797 1.001191 1581.177
## sigma_eps    6.713486 0.6434269  5.7619659  7.793386 1.004713 2175.764</code></pre>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="reliability-and-validity.html#cb112-1" tabindex="-1"></a><span class="co"># check systematic difference for rater in posterior</span></span>
<span id="cb112-2"><a href="reliability-and-validity.html#cb112-2" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m5<span class="fl">.2</span>)</span>
<span id="cb112-3"><a href="reliability-and-validity.html#cb112-3" tabindex="-1"></a><span class="fu">mean</span>(post<span class="sc">$</span>beta[,<span class="dv">1</span>] <span class="sc">-</span> post<span class="sc">$</span>beta[,<span class="dv">2</span>])</span></code></pre></div>
<pre><code>## [1] 2.456821</code></pre>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="reliability-and-validity.html#cb114-1" tabindex="-1"></a><span class="co"># ICC agreement:</span></span>
<span id="cb114-2"><a href="reliability-and-validity.html#cb114-2" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m5<span class="fl">.2</span>)</span>
<span id="cb114-3"><a href="reliability-and-validity.html#cb114-3" tabindex="-1"></a>(var_patients <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>sigma_alpha<span class="sc">^</span><span class="dv">2</span>))  <span class="co"># Between-patient variance</span></span></code></pre></div>
<pre><code>## [1] 241.5319</code></pre>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="reliability-and-validity.html#cb116-1" tabindex="-1"></a>(var_raters <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>sigma_beta<span class="sc">^</span><span class="dv">2</span>))     <span class="co"># Rater variance</span></span></code></pre></div>
<pre><code>## [1] 3.949248</code></pre>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="reliability-and-validity.html#cb118-1" tabindex="-1"></a>(var_residual <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>sigma_eps<span class="sc">^</span><span class="dv">2</span>))    <span class="co"># Residual variance</span></span></code></pre></div>
<pre><code>## [1] 45.48479</code></pre>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="reliability-and-validity.html#cb120-1" tabindex="-1"></a><span class="co"># ICC_agreement = </span></span>
<span id="cb120-2"><a href="reliability-and-validity.html#cb120-2" tabindex="-1"></a>var_patients <span class="sc">/</span> (var_patients <span class="sc">+</span> var_raters <span class="sc">+</span> var_residual)</span></code></pre></div>
<pre><code>## [1] 0.8301037</code></pre>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="reliability-and-validity.html#cb122-1" tabindex="-1"></a><span class="co"># 0.8033613 (sigma_alpha ~ dexp(1))</span></span>
<span id="cb122-2"><a href="reliability-and-validity.html#cb122-2" tabindex="-1"></a><span class="co"># 0.83 (sigma_alpha ~ dexp(0.5))</span></span>
<span id="cb122-3"><a href="reliability-and-validity.html#cb122-3" tabindex="-1"></a></span>
<span id="cb122-4"><a href="reliability-and-validity.html#cb122-4" tabindex="-1"></a><span class="co"># ICC (Single_fixed_raters) = ICC3 in psych output = </span></span>
<span id="cb122-5"><a href="reliability-and-validity.html#cb122-5" tabindex="-1"></a>var_patients <span class="sc">/</span> (var_patients <span class="sc">+</span> var_residual)</span></code></pre></div>
<pre><code>## [1] 0.8415256</code></pre>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="reliability-and-validity.html#cb124-1" tabindex="-1"></a><span class="co"># 0.8415256</span></span></code></pre></div>
<p>It should be noted that this ICC is very sensitive to the choice of the prior.
If you choose too agressive priors for the standard deviations <span class="math inline">\(\sigma_{\alpha},
\sigma_{\beta}, \sigma_{\varepsilon}\)</span>, you will get a too low ICC.</p>
<p>We will probably talk about this in the next lecture (Methodenvertiefung) in greater detail.
I have played around a little with the parameters in the exponential priors
to get the desired result which compares nicely to the two alternative methods below:
using the <code>psych</code> package and with the <code>lmer</code>
package. Both use a Frequentist random intercept model in the background.
Using a package like <code>psych</code> just gives a more convenient interface to
elicit the ICC.</p>
<p><strong><code>psych</code> package</strong>:</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="reliability-and-validity.html#cb125-1" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb125-2"><a href="reliability-and-validity.html#cb125-2" tabindex="-1"></a><span class="fu">library</span>(conflicted)</span>
<span id="cb125-3"><a href="reliability-and-validity.html#cb125-3" tabindex="-1"></a><span class="co"># needs wide format</span></span>
<span id="cb125-4"><a href="reliability-and-validity.html#cb125-4" tabindex="-1"></a><span class="co">#conflicts_prefer(dplyr::select)</span></span>
<span id="cb125-5"><a href="reliability-and-validity.html#cb125-5" tabindex="-1"></a>df_wide <span class="ot">&lt;-</span> df_long_bias <span class="sc">%&gt;%</span></span>
<span id="cb125-6"><a href="reliability-and-validity.html#cb125-6" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> Rater, <span class="at">values_from =</span> ROM)</span>
<span id="cb125-7"><a href="reliability-and-validity.html#cb125-7" tabindex="-1"></a>df_wide_values <span class="ot">&lt;-</span> df_wide <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>ID)</span>
<span id="cb125-8"><a href="reliability-and-validity.html#cb125-8" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">ICC</span>(df_wide_values) <span class="co"># ICC1 = 0.83</span></span></code></pre></div>
<pre><code>## Call: psych::ICC(x = df_wide_values)
## 
## Intraclass correlation coefficients 
##                          type  ICC  F df1 df2       p lower bound upper bound
## Single_raters_absolute   ICC1 0.83 11  49  50 1.1e-14        0.72        0.90
## Single_random_raters     ICC2 0.83 12  49  49 1.4e-15        0.71        0.91
## Single_fixed_raters      ICC3 0.85 12  49  49 1.4e-15        0.75        0.91
## Average_raters_absolute ICC1k 0.91 11  49  50 1.1e-14        0.84        0.95
## Average_random_raters   ICC2k 0.91 12  49  49 1.4e-15        0.83        0.95
## Average_fixed_raters    ICC3k 0.92 12  49  49 1.4e-15        0.86        0.95
## 
##  Number of subjects = 50     Number of Judges =  2
## See the help file for a discussion of the other 4 McGraw and Wong estimates,</code></pre>
<p><strong><code>lmer</code> package</strong>:</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="reliability-and-validity.html#cb127-1" tabindex="-1"></a><span class="co"># _lmer------</span></span>
<span id="cb127-2"><a href="reliability-and-validity.html#cb127-2" tabindex="-1"></a>m5<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lmer</span>(ROM <span class="sc">~</span> (<span class="dv">1</span> <span class="sc">|</span> ID) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Rater), <span class="at">data =</span> df_long_bias)</span>
<span id="cb127-3"><a href="reliability-and-validity.html#cb127-3" tabindex="-1"></a><span class="fu">summary</span>(m5<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: ROM ~ (1 | ID) + (1 | Rater)
##    Data: df_long_bias
## 
## REML criterion at convergence: 793.2
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.87448 -0.46270  0.00272  0.57820  1.45008 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  ID       (Intercept) 270.882  16.458  
##  Rater    (Intercept)   6.193   2.489  
##  Residual              47.557   6.896  
## Number of obs: 100, groups:  ID, 50; Rater, 2
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)   68.090      2.998   22.71</code></pre>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="reliability-and-validity.html#cb129-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">VarCorr</span>(m5<span class="fl">.3</span>), <span class="at">comp =</span> <span class="st">&quot;Variance&quot;</span>)</span></code></pre></div>
<pre><code>##  Groups   Name        Variance
##  ID       (Intercept) 270.882 
##  Rater    (Intercept)   6.193 
##  Residual              47.557</code></pre>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="reliability-and-validity.html#cb131-1" tabindex="-1"></a><span class="co"># Groups   Name        Variance</span></span>
<span id="cb131-2"><a href="reliability-and-validity.html#cb131-2" tabindex="-1"></a><span class="co"># ID       (Intercept) 270.882 </span></span>
<span id="cb131-3"><a href="reliability-and-validity.html#cb131-3" tabindex="-1"></a><span class="co"># Rater    (Intercept)   6.193 </span></span>
<span id="cb131-4"><a href="reliability-and-validity.html#cb131-4" tabindex="-1"></a><span class="co"># Residual              47.557 </span></span>
<span id="cb131-5"><a href="reliability-and-validity.html#cb131-5" tabindex="-1"></a></span>
<span id="cb131-6"><a href="reliability-and-validity.html#cb131-6" tabindex="-1"></a></span>
<span id="cb131-7"><a href="reliability-and-validity.html#cb131-7" tabindex="-1"></a><span class="co"># ICC (Single_random_raters) = ICC2 in psych output</span></span>
<span id="cb131-8"><a href="reliability-and-validity.html#cb131-8" tabindex="-1"></a><span class="fl">270.882</span> <span class="sc">/</span> (<span class="fl">270.882</span> <span class="sc">+</span> <span class="fl">6.193</span> <span class="sc">+</span> <span class="fl">47.557</span>) <span class="co"># </span></span></code></pre></div>
<pre><code>## [1] 0.8344279</code></pre>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="reliability-and-validity.html#cb133-1" tabindex="-1"></a><span class="co"># 0.8344279</span></span>
<span id="cb133-2"><a href="reliability-and-validity.html#cb133-2" tabindex="-1"></a></span>
<span id="cb133-3"><a href="reliability-and-validity.html#cb133-3" tabindex="-1"></a><span class="co"># ICC (Single_fixed_raters) = ICC3 in psych output</span></span>
<span id="cb133-4"><a href="reliability-and-validity.html#cb133-4" tabindex="-1"></a><span class="fl">270.882</span> <span class="sc">/</span> (<span class="fl">270.882</span> <span class="sc">+</span> <span class="fl">47.557</span>) <span class="co">#</span></span></code></pre></div>
<pre><code>## [1] 0.8506559</code></pre>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="reliability-and-validity.html#cb135-1" tabindex="-1"></a><span class="co"># 0.85</span></span></code></pre></div>
</div>
<div id="explanation-of-iccs-in-the-psych-output" class="section level3 hasAnchor" number="2.1.3">
<h3><span class="header-section-number">2.1.3</span> Explanation of ICCs in the <code>psych</code> output<a href="reliability-and-validity.html#explanation-of-iccs-in-the-psych-output" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If you want to know all the details, refer to <a href="https://d1wqtxts1xzle7.cloudfront.net/50483847/syarat_reliabilitas_icc-libre.pdf?1479841049=&amp;response-content-disposition=inline%3B+filename%3DIntraclass_Correlations_Uses_in_Assessin.pdf&amp;Expires=1740684631&amp;Signature=hHiFbcQD3PDVIyWDJ-bUhcm3WtsK19YhHm6FKtnafNdqsm9NhR6cr9lbCf~gVV5SYG1XlTwLlcfJkQ9Z-ahjmmNV893aWi5plo~yL4oZBEjrmFa9WCd7k6vzFTkri1Xbgfh~GyPARWXBtqABytovtL-RD1420Kw9qk150nw3-kUWcuvRiIc~r0y65XQaXf-V9mm~uXRFdUqec4Vs-Bwh~IrJfHWQASGgp8wZjzh2130MCP3-iaorxNn~79c~nm2f1aIl5WRqRXB6EIy8HlrNFpxNSt1pgTPZoZadEECM4qH395KLY5ijUnhoCDT9AmcOplPnFiC5t8dKW-n25ziofQ__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA">Shrout and Fleiss (1979)</a>.
The help-function <code>?psych::ICC</code> contains a relatively good and much shorter explanation.
The variance formulae given in the help-file are probably somewhat confusing.
We try to stick to the notation of the book.</p>
<p>Let’s talk about the first three <strong>ICCs in the <code>psych</code> output</strong>:.</p>
<ul>
<li><p><strong>Single_raters_absolute ICC1:</strong>
According to the help file: “Each target [i.e. patient] is rated by a different
judge [i.e. rater] and the judges are selected at random.” So, variability due to raters
is implied and cannot be disentangled.
This is formally not our situation, since we have only two raters and
50 patients. But for this case, we do not care who measures, since we do not
model it, hence, we cannot know if there are systematic differences between
the raters. There might as well be 50 raters doing their thing, or just 2 as in our case.
This is the ICC we calculated above; the overall ICC.
in the book and based on the following model:</p>
<p><span class="math display">\[Y_{ij} = \eta_i + \varepsilon_i\]</span>
where <span class="math inline">\(i \in {1,...,50}\)</span> is the patient and <span class="math inline">\(j \in {1,2}\)</span> is the <em>measurement</em>
(<span class="math inline">\(=50*2=100\)</span> rows in long format).
Note that we do not mention a rater here, since we do not care who took the
measurement. It is not part of the model. The ICC is then calculated as:</p>
<p><span class="math display">\[ICC = \frac{\sigma_{\eta}^2}{\sigma_{\eta}^2 + \sigma_{\varepsilon}^2}\]</span></p>
<p>whereas we could get the variance components from either the posterior in the Bayesian
setting or from the <code>lmer</code> output in the Frequentist setting.</p></li>
<li><p><strong>Single_random_raters ICC2:</strong>
ICC2 (<span class="math inline">\(=ICC_{agreement}\)</span> in the book) and ICC3 (<span class="math inline">\(=ICC_{consistency}\)</span> in the book)
are based on the <strong>same</strong> statistical model. The only difference is
that ICC2 assumes that the (in our case) 2 raters are randomly selected from a larger pool of raters,
hence, the rater variability must be explicitely considered and yields a potentially smaller
value for the ICC. Compared to ICC1, we have repeated measurements from the same raters
in 50 patients. That’s why we can model their bias. One observation would not be enough.
The help file says: “A random sample of k judges rate each target.
The measure is one of absolute agreement in the ratings.”
A random sample of k (2 in our case) judges means that we cannot rule out the variability
due to raters (you get a variety of them and their biases are different).</p>
<p><span class="math display">\[Y_{ij} = \eta_i + \beta_j + \varepsilon_i\]</span>
where <span class="math inline">\(i \in {1,...,50}\)</span> is the patient, <span class="math inline">\(j \in {1,2}\)</span> is the <strong>rater</strong>
(doing one measurement in each patient). The ICC is then calculated as:</p>
<p><span class="math display">\[ICC_{agreement} = \frac{\sigma_{\eta}^2}{\sigma_{\eta}^2 +\mathbf{\sigma_{rater}^2} + \sigma_{\varepsilon}^2}\]</span></p></li>
<li><p><strong>Single_fixed_raters ICC3:</strong>
ICC3 (<span class="math inline">\(=ICC_{consistency}\)</span> in the book) is based on the <strong>same model as ICC2</strong>,
but assumes that the raters are fixed.
This means that <strong>the raters are the same for all patients</strong> in the future study.
So, we have considered the rater variability in the model
(which was possible due to the repeated measurements from the same raters in 50 patients),
but do not care since Mary and Peter will be the people doing the future
measurements, not other therapists. If you fix a random variable
(raters in this case), variance is zero. The help file says:
“A fixed set of k judges rate each target.
There is no generalization to a larger population of judges.”
The ICC is then calculated as:</p>
<p><span class="math display">\[ICC_{consistency} = \frac{\sigma_{\eta}^2}{\sigma_{\eta}^2 + \sigma_{\varepsilon}^2}\]</span></p>
<p>ICC1 and ICC3 are <strong>not</strong> identical, since ICC1 does not consider the rater variability
in the model. They are based on <em>different</em> statistiacal models.
ICC2 and ICC3 are based on the <em>same</em> model.</p></li>
</ul>
<p>If there is no systematic difference between raters, all 3 ICCs and the Pearson
correlation (r) are the same (see Figure 5.3 in the book).</p>
<p><span class="math inline">\(ICC_{consistency}\)</span> vs. <span class="math inline">\(ICC_{agreement}\)</span>:
The latter is used, when we need Peter and Mary to concur in their measurements.
Patients coming to Peters practice will get the same (or very similar) “diagnosis” (ROM-value)
from Mary. When there is systematic difference (line is shifted downwards in Figure 5.3),
this cannot be guaranteed.
If we only need Peter and Mary to <em>rank</em> the patients in the same order,
we can use <span class="math inline">\(ICC_{consistency}\)</span>.</p>
</div>
<div id="summary-peter-and-mary-with-and-without-bias" class="section level3 hasAnchor" number="2.1.4">
<h3><span class="header-section-number">2.1.4</span> Summary Peter and Mary, with and without bias<a href="reliability-and-validity.html#summary-peter-and-mary-with-and-without-bias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Below, we summarize the results for the ICCs (calculated with <code>psych</code>)
for the unbiased and biased case (Mary measures on average 5 degrees more than peter).</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="reliability-and-validity.html#cb136-1" tabindex="-1"></a><span class="fu">library</span>(pacman)</span>
<span id="cb136-2"><a href="reliability-and-validity.html#cb136-2" tabindex="-1"></a><span class="fu">p_load</span>(conflicted, tidyverse, flextable)</span>
<span id="cb136-3"><a href="reliability-and-validity.html#cb136-3" tabindex="-1"></a></span>
<span id="cb136-4"><a href="reliability-and-validity.html#cb136-4" tabindex="-1"></a><span class="co"># Ensure select() from dplyr is used</span></span>
<span id="cb136-5"><a href="reliability-and-validity.html#cb136-5" tabindex="-1"></a><span class="co">#conflicted::conflicts_prefer(&quot;select&quot;, &quot;dplyr&quot;)</span></span>
<span id="cb136-6"><a href="reliability-and-validity.html#cb136-6" tabindex="-1"></a></span>
<span id="cb136-7"><a href="reliability-and-validity.html#cb136-7" tabindex="-1"></a><span class="co"># Unbiased ICC Calculation</span></span>
<span id="cb136-8"><a href="reliability-and-validity.html#cb136-8" tabindex="-1"></a>df_wide_unbiased <span class="ot">&lt;-</span> df_long <span class="sc">%&gt;%</span></span>
<span id="cb136-9"><a href="reliability-and-validity.html#cb136-9" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> Rater, <span class="at">values_from =</span> ROM)</span>
<span id="cb136-10"><a href="reliability-and-validity.html#cb136-10" tabindex="-1"></a>df_wide_values_unbiased <span class="ot">&lt;-</span> df_wide_unbiased <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>ID)</span>
<span id="cb136-11"><a href="reliability-and-validity.html#cb136-11" tabindex="-1"></a>icc_results_unbiased <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">ICC</span>(df_wide_values_unbiased)</span></code></pre></div>
<pre><code>## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="reliability-and-validity.html#cb138-1" tabindex="-1"></a><span class="co"># Extract relevant ICC values</span></span>
<span id="cb138-2"><a href="reliability-and-validity.html#cb138-2" tabindex="-1"></a>icc_unbiased_df <span class="ot">&lt;-</span> icc_results_unbiased<span class="sc">$</span>results <span class="sc">%&gt;%</span></span>
<span id="cb138-3"><a href="reliability-and-validity.html#cb138-3" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(type, ICC) <span class="sc">%&gt;%</span></span>
<span id="cb138-4"><a href="reliability-and-validity.html#cb138-4" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="st">`</span><span class="at">Unbiased ICC</span><span class="st">`</span> <span class="ot">=</span> ICC)</span>
<span id="cb138-5"><a href="reliability-and-validity.html#cb138-5" tabindex="-1"></a></span>
<span id="cb138-6"><a href="reliability-and-validity.html#cb138-6" tabindex="-1"></a><span class="co"># Biased ICC Calculation</span></span>
<span id="cb138-7"><a href="reliability-and-validity.html#cb138-7" tabindex="-1"></a>df_wide_biased <span class="ot">&lt;-</span> df_long_bias <span class="sc">%&gt;%</span></span>
<span id="cb138-8"><a href="reliability-and-validity.html#cb138-8" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> Rater, <span class="at">values_from =</span> ROM)</span>
<span id="cb138-9"><a href="reliability-and-validity.html#cb138-9" tabindex="-1"></a>df_wide_values_biased <span class="ot">&lt;-</span> df_wide_biased <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>ID)</span>
<span id="cb138-10"><a href="reliability-and-validity.html#cb138-10" tabindex="-1"></a>icc_results_biased <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">ICC</span>(df_wide_values_biased)</span>
<span id="cb138-11"><a href="reliability-and-validity.html#cb138-11" tabindex="-1"></a></span>
<span id="cb138-12"><a href="reliability-and-validity.html#cb138-12" tabindex="-1"></a><span class="co"># Extract relevant ICC values</span></span>
<span id="cb138-13"><a href="reliability-and-validity.html#cb138-13" tabindex="-1"></a>icc_biased_df <span class="ot">&lt;-</span> icc_results_biased<span class="sc">$</span>results <span class="sc">%&gt;%</span></span>
<span id="cb138-14"><a href="reliability-and-validity.html#cb138-14" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(type, ICC) <span class="sc">%&gt;%</span></span>
<span id="cb138-15"><a href="reliability-and-validity.html#cb138-15" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">rename</span>(<span class="st">`</span><span class="at">Biased ICC</span><span class="st">`</span> <span class="ot">=</span> ICC)</span>
<span id="cb138-16"><a href="reliability-and-validity.html#cb138-16" tabindex="-1"></a></span>
<span id="cb138-17"><a href="reliability-and-validity.html#cb138-17" tabindex="-1"></a>icc_merged_df <span class="ot">&lt;-</span> <span class="fu">left_join</span>(icc_unbiased_df, </span>
<span id="cb138-18"><a href="reliability-and-validity.html#cb138-18" tabindex="-1"></a>                           icc_biased_df, </span>
<span id="cb138-19"><a href="reliability-and-validity.html#cb138-19" tabindex="-1"></a>                           <span class="at">by =</span> <span class="st">&quot;type&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb138-20"><a href="reliability-and-validity.html#cb138-20" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)</span>
<span id="cb138-21"><a href="reliability-and-validity.html#cb138-21" tabindex="-1"></a></span>
<span id="cb138-22"><a href="reliability-and-validity.html#cb138-22" tabindex="-1"></a>ft <span class="ot">&lt;-</span> <span class="fu">flextable</span>(icc_merged_df) <span class="sc">%&gt;%</span></span>
<span id="cb138-23"><a href="reliability-and-validity.html#cb138-23" tabindex="-1"></a>  flextable<span class="sc">::</span><span class="fu">set_header_labels</span>(<span class="at">type =</span> <span class="st">&quot;ICC Type&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb138-24"><a href="reliability-and-validity.html#cb138-24" tabindex="-1"></a>  flextable<span class="sc">::</span><span class="fu">set_caption</span>(<span class="st">&quot;Intraclass Correlation Coefficients - Unbiased vs. Biased&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb138-25"><a href="reliability-and-validity.html#cb138-25" tabindex="-1"></a>  flextable<span class="sc">::</span><span class="fu">set_table_properties</span>(<span class="at">width =</span> .<span class="dv">5</span>, <span class="at">layout =</span> <span class="st">&quot;autofit&quot;</span>)</span>
<span id="cb138-26"><a href="reliability-and-validity.html#cb138-26" tabindex="-1"></a>ft</span></code></pre></div>
<div class="tabwid"><style>.cl-c88a6a96{table-layout:auto;width:50%;}.cl-c8875db0{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-c888a0da{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-c888a0e4{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-c888ae2c{background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c888ae36{background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c888ae37{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c888ae38{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c888ae40{background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c888ae41{background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-c88a6a96'>
<caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span id="tab:unnamed-chunk-10">Table 2.1: </span><span>Intraclass Correlation Coefficients - Unbiased vs. Biased</span></caption>
<thead><tr style="overflow-wrap:break-word;"><th class="cl-c888ae2c"><p class="cl-c888a0da"><span class="cl-c8875db0">ICC Type</span></p></th><th class="cl-c888ae36"><p class="cl-c888a0e4"><span class="cl-c8875db0">Unbiased ICC</span></p></th><th class="cl-c888ae36"><p class="cl-c888a0e4"><span class="cl-c8875db0">Biased ICC</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-c888ae37"><p class="cl-c888a0da"><span class="cl-c8875db0">ICC1</span></p></td><td class="cl-c888ae38"><p class="cl-c888a0e4"><span class="cl-c8875db0">0.8512574</span></p></td><td class="cl-c888ae38"><p class="cl-c888a0e4"><span class="cl-c8875db0">0.8328336</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c888ae37"><p class="cl-c888a0da"><span class="cl-c8875db0">ICC2</span></p></td><td class="cl-c888ae38"><p class="cl-c888a0e4"><span class="cl-c8875db0">0.8512574</span></p></td><td class="cl-c888ae38"><p class="cl-c888a0e4"><span class="cl-c8875db0">0.8344281</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c888ae40"><p class="cl-c888a0da"><span class="cl-c8875db0">ICC3</span></p></td><td class="cl-c888ae41"><p class="cl-c888a0e4"><span class="cl-c8875db0">0.8512574</span></p></td><td class="cl-c888ae41"><p class="cl-c888a0e4"><span class="cl-c8875db0">0.8506562</span></p></td></tr></tbody></table></div>
<p>The <strong>left column</strong> shows that the ICCs are identical for the <strong>unbiased case</strong>.
Specifically, ICC2 (=<span class="math inline">\(ICC_{agreement}\)</span> in the book) and
ICC3 (<span class="math inline">\(ICC_{consistency}\)</span> in the book) are based on the same model which explicitely
considers a potential bias between the raters. Since there is none,
the ICCs are the same.</p>
<p>In the <strong>biased case</strong>, there <em>is</em> as systematic difference between Mary and Peter.</p>
<p><strong>ICC1</strong> does not care about it and shows a somewhat lower value compared to
before (<span class="math inline">\(0.833\)</span>). The reason is because the agreement line is in a plot with
Mary on Y and Peter on X shifted upwards by 5 degrees.
If you would introduce a bias of 15 degrees, the ICC would
be even lower (<span class="math inline">\(ICC1 = 0.61\)</span>, <span class="math inline">\(ICC2 = 0.65\)</span> -&gt; verify as exercise).
The unbiased column would of course stay the same.</p>
<p><strong>ICC2</strong> now considers the bias of 5 degrees. The model knows about the shift.
If we compare the variance components of ICC1 and ICC2, we see:</p>
<pre><code>## [1] &quot;Model for ICC1: ROM ~ (1 | ID)&quot;</code></pre>
<pre><code>##  Groups   Name        Variance
##  ID       (Intercept) 267.79  
##  Residual              53.75</code></pre>
<pre><code>## [1] &quot;Model for ICC2 (and 3): ROM ~ (1 | ID) + (1 | Rater)&quot;</code></pre>
<pre><code>##  Groups   Name        Variance
##  ID       (Intercept) 270.882 
##  Rater    (Intercept)   6.193 
##  Residual              47.557</code></pre>
<p>The residual variance is smaller in the model with the rater effect.
The model explains the data better, since it knows about the bias.</p>
<p>Look at the <span class="math inline">\(\sigma_{\varepsilon}\)</span> of the two models, they add up:</p>
<p><span class="math display">\[\sigma_{\varepsilon, ICC1}^2 = \sigma_{\varepsilon, ICC23}^2 + \sigma_{Rater}^2\]</span>
<span class="math display">\[53.75 = 47.557 + 6.193\]</span></p>
<p>Hence, we just split up the error differently by considering the bias.
The patient variability (<code>ID Variance</code> in the output) is slightly higher:
<span class="math inline">\(270.882\)</span> compared to <span class="math inline">\(267.79\)</span> before.
In the first model, patient variability was conflated with rater variation because rater effects
were not explicitly modeled. For this reason, <code>ID Variance</code> increases slightly.
It is a rather small increase, so ICC1 and ICC2 are not that different.</p>
<p>For a bias of 15 degrees, the additivity of the variances remains.
The patient variability increases from <span class="math inline">\(223.89\)</span> (ICC1) to <span class="math inline">\(270.882\)</span> (ICC2),
hence the difference in ICCs is larger (<span class="math inline">\(ICC1=0.613\)</span> vs. <span class="math inline">\(ICC2=0.657\)</span>).</p>
<p><strong>ICC3</strong> considers the bias in the model but does not include it in the measurement
error since the raters are fixed.</p>
</div>
<div id="difference-between-correlation-and-icc" class="section level3 hasAnchor" number="2.1.5">
<h3><span class="header-section-number">2.1.5</span> Difference between correlation and ICC<a href="reliability-and-validity.html#difference-between-correlation-and-icc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we do not introduce a bias in the data, the correlation coefficient
is the same as the ICC (as seen above). On page 110, Figure 5.3, the authors show nicely
what the difference is between the correlation coefficient and the ICC.
It is also shown how <span class="math inline">\(ICC_{agreement}\)</span> and <span class="math inline">\(ICC_{consistency}\)</span> change with the bias.</p>
<p><span class="math inline">\(ICC_{consistency}\)</span> stays <span class="math inline">\(1\)</span> if bias is introduced (assuming a hypothetical
perfect agreement before). Peter and Mary still rank the patients
in the same order.</p>
<p>Correlation <span class="math inline">\(r\)</span> is always 1, no matter at what slope (<span class="math inline">\(\ne 0\)</span>) the line is.
It measures the strength and direction of the <em>linear</em> relationship between two variables.</p>
<p><span class="math inline">\(ICC_{agreement}\)</span> changes as soon as you depart from the 45 degree line
with respect to slope or
shift the line up or down (i.e., introduce a bias).</p>
<p>This is a good point in time to think for a moment about the type of measurement
for agreement with respect to <strong>costs</strong>. The ICC below weights each measurement
equally, although one larger outlier (large discrepancy between Peter and Mary)
may influence the ICC notably (exercise later). One could easily think of a situation where
overall agreement measure like the ICC is not adequate since,
for instance, exceeding a certain
difference threshold could decide between life and death.</p>
</div>
<div id="bad-news-about-the-icc" class="section level3 hasAnchor" number="2.1.6">
<h3><span class="header-section-number">2.1.6</span> Bad news about the ICC?<a href="reliability-and-validity.html#bad-news-about-the-icc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s try to expand our intuitive understanding of what an ICC of 0.8 or so means.
For simplicity, we take the overall ICC, which is equal to the correlation coefficient,
if there is no bias present.</p>
<p>The following example demonstrates the meaning of the Test-Retest reliability of
the Hospital Anxiety and Depression Scale - Anxiety subscale (HADS-A). We could take
all kinds of other scores where ICC values and a
<a href="https://en.wikipedia.org/wiki/Minimal_important_difference">minimally clinically important difference (MCID)</a>
is given. Briefly, the MCID is the smallest change in a score that is considered
important to the patient. For example, a 5% change in BMI is (in some populations)
considered meaningful.</p>
<p>Specifically, we:</p>
<ul>
<li>Simulate two correlated measurement at two time points (TP1 and TP2)
to get predetermined ICC (<span class="math inline">\(=\rho\)</span>).</li>
<li>Calculate the Intraclass Correlation Coefficient (ICC).</li>
<li>Compare the Minimal Clinically Important Difference (MCID) to prediction intervals.</li>
<li>Visualize how often a clinically meaningful change of 1.68 points is
detected, even if no real change has occurred.</li>
</ul>
<p>The code can be found <a href="https://github.com/jdegenfellner/ICC_MCID/blob/main/ICC_MCID.R">here</a>
and in the github repo of the script. In the code, the sources for the ICC and MCID are
cited.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="reliability-and-validity.html#cb143-1" tabindex="-1"></a><span class="co"># ICC and Test-Retest-Reliability</span></span>
<span id="cb143-2"><a href="reliability-and-validity.html#cb143-2" tabindex="-1"></a></span>
<span id="cb143-3"><a href="reliability-and-validity.html#cb143-3" tabindex="-1"></a><span class="fu">library</span>(pacman)</span>
<span id="cb143-4"><a href="reliability-and-validity.html#cb143-4" tabindex="-1"></a><span class="fu">p_load</span>(tidyverse, lme4, conflicted, psych, MASS)</span>
<span id="cb143-5"><a href="reliability-and-validity.html#cb143-5" tabindex="-1"></a></span>
<span id="cb143-6"><a href="reliability-and-validity.html#cb143-6" tabindex="-1"></a><span class="co"># MCID Minimal Clinically Important Difference---------</span></span>
<span id="cb143-7"><a href="reliability-and-validity.html#cb143-7" tabindex="-1"></a></span>
<span id="cb143-8"><a href="reliability-and-validity.html#cb143-8" tabindex="-1"></a><span class="co"># HADS score---------</span></span>
<span id="cb143-9"><a href="reliability-and-validity.html#cb143-9" tabindex="-1"></a><span class="co"># The Hospital Anxiety and Depression Scale </span></span>
<span id="cb143-10"><a href="reliability-and-validity.html#cb143-10" tabindex="-1"></a></span>
<span id="cb143-11"><a href="reliability-and-validity.html#cb143-11" tabindex="-1"></a><span class="co"># Test-Retest-Reliability:</span></span>
<span id="cb143-12"><a href="reliability-and-validity.html#cb143-12" tabindex="-1"></a><span class="co"># https://doi.org/10.1016/S1361-9004(02)00029-8</span></span>
<span id="cb143-13"><a href="reliability-and-validity.html#cb143-13" tabindex="-1"></a></span>
<span id="cb143-14"><a href="reliability-and-validity.html#cb143-14" tabindex="-1"></a><span class="co"># Use the numbers from here (Table 1):</span></span>
<span id="cb143-15"><a href="reliability-and-validity.html#cb143-15" tabindex="-1"></a><span class="co"># https://www.sciencedirect.com/science/article/abs/pii/S1361900402000298</span></span>
<span id="cb143-16"><a href="reliability-and-validity.html#cb143-16" tabindex="-1"></a><span class="co"># for demonstration purposes.</span></span>
<span id="cb143-17"><a href="reliability-and-validity.html#cb143-17" tabindex="-1"></a></span>
<span id="cb143-18"><a href="reliability-and-validity.html#cb143-18" tabindex="-1"></a><span class="co"># Minimal Clinically Important Difference (MCID) for HADS-A:</span></span>
<span id="cb143-19"><a href="reliability-and-validity.html#cb143-19" tabindex="-1"></a><span class="co"># https://pmc.ncbi.nlm.nih.gov/articles/PMC2459149/</span></span>
<span id="cb143-20"><a href="reliability-and-validity.html#cb143-20" tabindex="-1"></a><span class="co"># Not exactly the same population as shift workers, but suffices for demonstration purposes.</span></span>
<span id="cb143-21"><a href="reliability-and-validity.html#cb143-21" tabindex="-1"></a><span class="co"># MCID HADS anxiety score and 1.68 (1.48–1.87)</span></span>
<span id="cb143-22"><a href="reliability-and-validity.html#cb143-22" tabindex="-1"></a></span>
<span id="cb143-23"><a href="reliability-and-validity.html#cb143-23" tabindex="-1"></a><span class="co"># Simplification: Score is deemed to be continuous.</span></span>
<span id="cb143-24"><a href="reliability-and-validity.html#cb143-24" tabindex="-1"></a></span>
<span id="cb143-25"><a href="reliability-and-validity.html#cb143-25" tabindex="-1"></a><span class="co"># Create 2 correlated measurements:</span></span>
<span id="cb143-26"><a href="reliability-and-validity.html#cb143-26" tabindex="-1"></a><span class="co"># Use HADS-A Anxiety subscale</span></span>
<span id="cb143-27"><a href="reliability-and-validity.html#cb143-27" tabindex="-1"></a><span class="co"># Use n=100, instead of n=24 for more stability</span></span>
<span id="cb143-28"><a href="reliability-and-validity.html#cb143-28" tabindex="-1"></a></span>
<span id="cb143-29"><a href="reliability-and-validity.html#cb143-29" tabindex="-1"></a>sigma1 <span class="ot">&lt;-</span> <span class="fl">3.93</span>  <span class="co"># Standard deviation of variable 1</span></span>
<span id="cb143-30"><a href="reliability-and-validity.html#cb143-30" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> <span class="fl">3.52</span>  <span class="co"># Standard deviation of variable 2</span></span>
<span id="cb143-31"><a href="reliability-and-validity.html#cb143-31" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.82</span>    <span class="co"># Correlation</span></span>
<span id="cb143-32"><a href="reliability-and-validity.html#cb143-32" tabindex="-1"></a>cov_matrix <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(sigma1<span class="sc">^</span><span class="dv">2</span>, rho <span class="sc">*</span> sigma1 <span class="sc">*</span> sigma2,</span>
<span id="cb143-33"><a href="reliability-and-validity.html#cb143-33" tabindex="-1"></a>                       rho <span class="sc">*</span> sigma1 <span class="sc">*</span> sigma2, sigma2<span class="sc">^</span><span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb143-34"><a href="reliability-and-validity.html#cb143-34" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb143-35"><a href="reliability-and-validity.html#cb143-35" tabindex="-1"></a></span>
<span id="cb143-36"><a href="reliability-and-validity.html#cb143-36" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">188</span>)  <span class="co"># For reproducibility</span></span>
<span id="cb143-37"><a href="reliability-and-validity.html#cb143-37" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">mvrnorm</span>(<span class="at">n =</span> n, <span class="at">mu =</span> <span class="fu">c</span>(<span class="fl">7.92</span>, <span class="fl">7.83</span>), <span class="at">Sigma =</span> cov_matrix)</span>
<span id="cb143-38"><a href="reliability-and-validity.html#cb143-38" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(samples)</span>
<span id="cb143-39"><a href="reliability-and-validity.html#cb143-39" tabindex="-1"></a><span class="fu">colnames</span>(df) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;TP1&quot;</span>, <span class="st">&quot;TP2&quot;</span>)</span>
<span id="cb143-40"><a href="reliability-and-validity.html#cb143-40" tabindex="-1"></a></span>
<span id="cb143-41"><a href="reliability-and-validity.html#cb143-41" tabindex="-1"></a><span class="fu">plot</span>(df, <span class="at">main =</span> <span class="st">&quot;Scatterplot of Multivariate Normal Samples&quot;</span>,</span>
<span id="cb143-42"><a href="reliability-and-validity.html#cb143-42" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;TP1&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;TP2&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">col =</span> <span class="fu">rgb</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>))</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="reliability-and-validity.html#cb144-1" tabindex="-1"></a><span class="co"># https://en.wikipedia.org/wiki/Intraclass_correlation#Modern_ICC_definitions:_simpler_formula_but_positive_bias</span></span>
<span id="cb144-2"><a href="reliability-and-validity.html#cb144-2" tabindex="-1"></a><span class="co"># ICC should be the correlation within the group (i.e. patient)</span></span>
<span id="cb144-3"><a href="reliability-and-validity.html#cb144-3" tabindex="-1"></a></span>
<span id="cb144-4"><a href="reliability-and-validity.html#cb144-4" tabindex="-1"></a><span class="fu">cor</span>(df<span class="sc">$</span>TP1, df<span class="sc">$</span>TP2, <span class="at">method =</span> <span class="st">&quot;pearson&quot;</span>) <span class="co"># ~0.8-0.9</span></span></code></pre></div>
<pre><code>## [1] 0.8184881</code></pre>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="reliability-and-validity.html#cb146-1" tabindex="-1"></a><span class="fu">ICC</span>(df) <span class="co"># 0.82</span></span></code></pre></div>
<pre><code>## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<pre><code>## Call: ICC(x = df)
## 
## Intraclass correlation coefficients 
##                          type  ICC  F df1 df2       p lower bound upper bound
## Single_raters_absolute   ICC1 0.82 10  99 100 5.6e-26        0.74        0.87
## Single_random_raters     ICC2 0.82 10  99  99 8.7e-26        0.74        0.87
## Single_fixed_raters      ICC3 0.82 10  99  99 8.7e-26        0.74        0.87
## Average_raters_absolute ICC1k 0.90 10  99 100 5.6e-26        0.85        0.93
## Average_random_raters   ICC2k 0.90 10  99  99 8.7e-26        0.85        0.93
## Average_fixed_raters    ICC3k 0.90 10  99  99 8.7e-26        0.85        0.93
## 
##  Number of subjects = 100     Number of Judges =  2
## See the help file for a discussion of the other 4 McGraw and Wong estimates,</code></pre>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="reliability-and-validity.html#cb149-1" tabindex="-1"></a><span class="co"># check manually</span></span>
<span id="cb149-2"><a href="reliability-and-validity.html#cb149-2" tabindex="-1"></a>df_mod <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span>n, df<span class="sc">$</span>TP1, df<span class="sc">$</span>TP2)</span>
<span id="cb149-3"><a href="reliability-and-validity.html#cb149-3" tabindex="-1"></a><span class="fu">names</span>(df_mod) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;id&quot;</span>, <span class="st">&quot;TP1&quot;</span>, <span class="st">&quot;TP2&quot;</span>)</span>
<span id="cb149-4"><a href="reliability-and-validity.html#cb149-4" tabindex="-1"></a>df_mod_long <span class="ot">&lt;-</span> df_mod <span class="sc">%&gt;%</span> <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">c</span>(TP1, TP2), <span class="at">names_to =</span> <span class="st">&quot;time_point&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;score&quot;</span>)</span>
<span id="cb149-5"><a href="reliability-and-validity.html#cb149-5" tabindex="-1"></a>mod <span class="ot">&lt;-</span> lme4<span class="sc">::</span><span class="fu">lmer</span>(score <span class="sc">~</span> time_point <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>id), <span class="at">data =</span> df_mod_long)</span>
<span id="cb149-6"><a href="reliability-and-validity.html#cb149-6" tabindex="-1"></a>variance_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">summary</span>(mod)<span class="sc">$</span>varcor)</span>
<span id="cb149-7"><a href="reliability-and-validity.html#cb149-7" tabindex="-1"></a><span class="co"># ICC=</span></span>
<span id="cb149-8"><a href="reliability-and-validity.html#cb149-8" tabindex="-1"></a>variance_df<span class="sc">$</span>sdcor[<span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> (variance_df<span class="sc">$</span>sdcor[<span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> variance_df<span class="sc">$</span>sdcor[<span class="dv">2</span>]<span class="sc">^</span><span class="dv">2</span>) <span class="co"># ~0.9</span></span></code></pre></div>
<pre><code>## [1] 0.8170566</code></pre>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="reliability-and-validity.html#cb151-1" tabindex="-1"></a><span class="co"># cor and ICC are very very similar, should actually be identical.</span></span>
<span id="cb151-2"><a href="reliability-and-validity.html#cb151-2" tabindex="-1"></a></span>
<span id="cb151-3"><a href="reliability-and-validity.html#cb151-3" tabindex="-1"></a><span class="co"># check</span></span>
<span id="cb151-4"><a href="reliability-and-validity.html#cb151-4" tabindex="-1"></a><span class="fu">mean</span>(df<span class="sc">$</span>TP1)</span></code></pre></div>
<pre><code>## [1] 7.964553</code></pre>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="reliability-and-validity.html#cb153-1" tabindex="-1"></a><span class="fu">mean</span>(df<span class="sc">$</span>TP2) </span></code></pre></div>
<pre><code>## [1] 7.782436</code></pre>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="reliability-and-validity.html#cb155-1" tabindex="-1"></a><span class="co">#data.frame(TP1 = df$TP1, TP2 = df$TP2) %&gt;% </span></span>
<span id="cb155-2"><a href="reliability-and-validity.html#cb155-2" tabindex="-1"></a><span class="co">#  ggplot(aes(x = TP1, y = TP2)) +</span></span>
<span id="cb155-3"><a href="reliability-and-validity.html#cb155-3" tabindex="-1"></a><span class="co">#  geom_point() +</span></span>
<span id="cb155-4"><a href="reliability-and-validity.html#cb155-4" tabindex="-1"></a><span class="co">#  xlab(&quot;Measurement of patients at time point 1&quot;) +</span></span>
<span id="cb155-5"><a href="reliability-and-validity.html#cb155-5" tabindex="-1"></a><span class="co">#  ylab(&quot;Measurement of the same patients at time point 2&quot;)</span></span>
<span id="cb155-6"><a href="reliability-and-validity.html#cb155-6" tabindex="-1"></a></span>
<span id="cb155-7"><a href="reliability-and-validity.html#cb155-7" tabindex="-1"></a><span class="co"># Range for HADS-A should be 0-21 </span></span>
<span id="cb155-8"><a href="reliability-and-validity.html#cb155-8" tabindex="-1"></a><span class="co"># (according to &quot;The Hospital Anxiety and Depression Scale, Zigmond &amp; Snaith, 1983&quot;)</span></span>
<span id="cb155-9"><a href="reliability-and-validity.html#cb155-9" tabindex="-1"></a></span>
<span id="cb155-10"><a href="reliability-and-validity.html#cb155-10" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">TP1 =</span> df<span class="sc">$</span>TP1, <span class="at">TP2 =</span> df<span class="sc">$</span>TP2) <span class="sc">%&gt;%</span> </span>
<span id="cb155-11"><a href="reliability-and-validity.html#cb155-11" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(TP1 <span class="sc">&gt;=</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb155-12"><a href="reliability-and-validity.html#cb155-12" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(TP2 <span class="sc">&gt;=</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span> <span class="co"># negative not possible</span></span>
<span id="cb155-13"><a href="reliability-and-validity.html#cb155-13" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(TP1 <span class="sc">&lt;=</span> <span class="dv">21</span>) <span class="sc">%&gt;%</span></span>
<span id="cb155-14"><a href="reliability-and-validity.html#cb155-14" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(TP2 <span class="sc">&lt;=</span> <span class="dv">21</span>) <span class="co"># max. score is 21</span></span>
<span id="cb155-15"><a href="reliability-and-validity.html#cb155-15" tabindex="-1"></a>df</span></code></pre></div>
<pre><code>##          TP1       TP2
## 1  13.003089 14.539674
## 2   6.980669  9.312346
## 3  17.751972 12.957041
## 4  10.344489  6.995323
## 5   7.861347  7.568915
## 6  12.892886 11.703021
## 7   5.478497  7.952075
## 8   9.583384  7.515242
## 9   7.519451  4.043160
## 10 11.499240 11.652541
## 11  6.468033  6.660218
## 12  6.048513  3.471018
## 13  7.697834  9.065112
## 14 12.254369  8.811619
## 15  1.614857  4.614998
## 16 10.619077 10.125575
## 17  9.419930  8.518226
## 18  2.937867  4.456727
## 19  8.236834 11.196117
## 20  8.954668 12.675367
## 21 12.320423 12.768905
## 22 12.314754 10.081370
## 23  2.160930  6.959311
## 24  6.832022  6.613443
## 25  1.093221  4.571882
## 26  9.725573  9.440133
## 27  1.355585  4.171266
## 28  7.752631  9.028429
## 29  8.764755  5.020493
## 30  6.347606  3.694110
## 31  5.375775  4.932552
## 32 11.278457 10.079779
## 33  6.740993  6.092677
## 34  5.812009  4.668937
## 35  4.349329  6.225931
## 36  9.895140 12.126645
## 37 11.148574  9.213335
## 38  2.047422  2.430490
## 39  6.486131  6.032311
## 40  5.645763  7.611138
## 41  6.726079 10.071178
## 42  5.755609  7.947849
## 43 10.642786  9.117806
## 44  5.141220  5.304112
## 45  2.642085  1.933020
## 46  7.684671  6.640758
## 47  9.262502  8.538370
## 48 16.254728 15.559716
## 49  7.156983  6.978574
## 50 12.081541 10.935277
## 51 11.764108  9.705782
## 52 11.558231 10.001998
## 53  7.207230  8.702822
## 54 13.271195 12.305426
## 55  8.662632  9.794167
## 56  7.202986  3.372489
## 57  5.857393 10.673803
## 58 12.606715  8.961083
## 59 11.081861 13.549278
## 60  4.900769  5.337160
## 61 15.309336 11.034889
## 62 14.589373 13.720623
## 63 13.671753 10.925029
## 64 12.180305 12.781404
## 65  1.762711  5.561035
## 66  3.140391  6.372191
## 67  5.492213  5.996299
## 68  4.466991  8.914347
## 69  2.502974  2.742313
## 70 12.667048  9.000329
## 71  4.580641  6.028937
## 72 11.858807 10.368234
## 73  4.537198  2.709857
## 74  7.419888 10.998858
## 75  4.879237  4.827545
## 76 13.618764  9.062266
## 77 14.472807 14.418930
## 78  7.952580  7.896180
## 79  1.912410  3.428163
## 80  7.801004  2.616797
## 81 10.336987 11.858491
## 82  8.417477 10.399787
## 83  5.491992  7.532053
## 84  7.596043  3.712851
## 85  6.912368  8.655686
## 86  6.201155  2.107871
## 87 11.707088 13.145075
## 88  3.443512  1.810893
## 89 12.406231 12.175912
## 90  7.231295  8.403967
## 91 11.070856 10.877902
## 92 14.508512 13.754604
## 93  9.936188 10.610818
## 94  6.590862  3.507825
## 95 11.660322 10.722280</code></pre>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="reliability-and-validity.html#cb157-1" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(TP2 <span class="sc">~</span> TP1, <span class="at">data =</span> df)</span>
<span id="cb157-2"><a href="reliability-and-validity.html#cb157-2" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod, df, <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>)</span>
<span id="cb157-3"><a href="reliability-and-validity.html#cb157-3" tabindex="-1"></a></span>
<span id="cb157-4"><a href="reliability-and-validity.html#cb157-4" tabindex="-1"></a><span class="co"># How wide are the prediction intervals for a patient?</span></span>
<span id="cb157-5"><a href="reliability-and-validity.html#cb157-5" tabindex="-1"></a><span class="fu">as.data.frame</span>(pred) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">width_prediction_interval =</span> upr <span class="sc">-</span> lwr) <span class="co"># width of the prediction interval 8-10 points!</span></span></code></pre></div>
<pre><code>##          fit         lwr       upr width_prediction_interval
## 1  11.517789  7.32000445 15.715573                  8.395568
## 2   7.260698  3.09356695 11.427829                  8.334262
## 3  14.874649 10.57640522 19.172893                  8.596488
## 4   9.638494  5.46784345 13.809144                  8.341301
## 5   7.883226  3.71851506 12.047937                  8.329422
## 6  11.439889  7.24365214 15.636126                  8.392473
## 7   6.198852  2.02213714 10.375568                  8.353431
## 8   9.100489  4.93366030 13.267318                  8.333658
## 9   7.641549  3.47617950 11.806918                  8.330738
## 10 10.454757  6.27494432 14.634571                  8.359626
## 11  6.898329  2.72869927 11.067959                  8.339260
## 12  6.601781  2.42951087 10.774051                  8.344541
## 13  7.767643  3.60266181 11.932624                  8.329962
## 14 10.988538  6.80055090 15.176525                  8.375974
## 15  3.467747 -0.76481930  7.700313                  8.465132
## 16  9.832593  5.66013066 14.005055                  8.344925
## 17  8.984947  4.81870889 13.151186                  8.332477
## 18  4.402947  0.19450442  8.611390                  8.416885
## 19  8.148648  3.98424793 12.313048                  8.328800
## 20  8.656066  4.49106133 12.821072                  8.330010
## 21 11.035230  6.84644646 15.224014                  8.377568
## 22 11.031223  6.84250820 15.219938                  8.377430
## 23  3.853751 -0.36823502  8.075737                  8.443972
## 24  7.155623  2.98785021 11.323396                  8.335546
## 25  3.099016 -1.14446756  7.342499                  8.486967
## 26  9.200999  5.03359021 13.368407                  8.334817
## 27  3.284474 -0.95341998  7.522367                  8.475787
## 28  7.806378  3.64149615 11.971259                  8.329763
## 29  8.521822  4.35713015 12.686514                  8.329383
## 30  6.813202  2.64286933 10.983535                  8.340666
## 31  6.126241  1.94861984 10.303862                  8.355242
## 32 10.298692  6.12094325 14.476441                  8.355497
## 33  7.091277  2.92307764 11.259477                  8.336399
## 34  6.434603  2.26060789 10.608598                  8.347990
## 35  5.400673  1.21224884  9.589097                  8.376848
## 36  9.320861  5.15268035 13.489042                  8.336361
## 37 10.206881  6.03027765 14.383484                  8.353206
## 38  3.773515 -0.45059795  7.997629                  8.448227
## 39  6.911122  2.74159427 11.080650                  8.339056
## 40  6.317088  2.14177936 10.492397                  8.350617
## 41  7.080735  2.91246298 11.249007                  8.336544
## 42  6.394735  2.22030395 10.569166                  8.348862
## 43  9.849352  5.67672294 14.021982                  8.345259
## 44  5.960440  1.78063088 10.140249                  8.359619
## 45  4.193867 -0.01952182  8.407256                  8.426777
## 46  7.758338  3.59333195 11.923345                  8.330013
## 47  8.873666  4.70791894 13.039413                  8.331494
## 48 13.816287  9.55673194 18.075843                  8.519111
## 49  7.385330  3.21887319 11.551787                  8.332914
## 50 10.866371  6.68040625 15.052336                  8.371929
## 51 10.641986  6.45950156 14.824470                  8.364969
## 52 10.496456  6.31606656 14.676846                  8.360780
## 53  7.420848  3.25456616 11.587130                  8.332564
## 54 11.707306  7.50560608 15.909006                  8.403400
## 55  8.449634  4.28506471 12.614202                  8.329138
## 56  7.417848  3.25155183 11.584145                  8.332593
## 57  6.466683  2.29303270 10.640334                  8.347301
## 58 11.237603  7.04521442 15.429991                  8.384777
## 59 10.159723  5.98368848 14.335757                  8.352069
## 60  5.790471  1.60824613  9.972696                  8.364450
## 61 13.148015  8.90959977 17.386429                  8.476830
## 62 12.639092  8.41504000 16.863143                  8.448103
## 63 11.990450  7.78250179 16.198399                  8.415897
## 64 10.936184  6.74907482 15.123294                  8.374219
## 65  3.572261 -0.65735481  7.801876                  8.459231
## 66  4.546106  0.34090074  8.751312                  8.410411
## 67  6.208548  2.03195085 10.385144                  8.353194
## 68  5.483845  1.29682048  9.670870                  8.374049
## 69  4.095533 -0.12027142  8.311337                  8.431609
## 70 11.280250  7.08707078 15.473429                  8.386359
## 71  5.564181  1.37846891  9.749893                  8.371425
## 72 10.708926  6.52543503 14.892417                  8.366982
## 73  5.533472  1.34726300  9.719682                  8.372419
## 74  7.571170  3.40554231 11.736798                  8.331256
## 75  5.775251  1.59280130  9.957701                  8.364900
## 76 11.952994  7.74589920 16.160088                  8.414189
## 77 12.556694  8.33482530 16.778563                  8.443737
## 78  7.947716  3.78312039 12.112312                  8.329192
## 79  3.678079 -0.54861400  7.904772                  8.453386
## 80  7.840572  3.67577039 12.005373                  8.329602
## 81  9.633192  5.46258745 13.803796                  8.341208
## 82  8.276340  4.11193632 12.440744                  8.328808
## 83  6.208392  2.03179294 10.384990                  8.353197
## 84  7.695690  3.53049953 11.860881                  8.330381
## 85  7.212418  3.04500055 11.379836                  8.334835
## 86  6.709680  2.53843261 10.880928                  8.342495
## 87 10.601680  6.41978859 14.783572                  8.363783
## 88  4.760375  0.55978683  8.960963                  8.401176
## 89 11.095886  6.90604714 15.285724                  8.379677
## 90  7.437859  3.27165782 11.604060                  8.332402
## 91 10.151944  5.97600166 14.327886                  8.351884
## 92 12.581933  8.35939957 16.804466                  8.445066
## 93  9.349877  5.18149616 13.518258                  8.336761
## 94  6.985154  2.81619604 11.154112                  8.337916
## 95 10.568622  6.38720944 14.750034                  8.362825</code></pre>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="reliability-and-validity.html#cb159-1" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb159-2"><a href="reliability-and-validity.html#cb159-2" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">TP1 =</span> <span class="dv">10</span>), <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>) <span class="co"># 95% prediction interval for a patient with a score of 10 at time point 1.</span></span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 9.394984 5.226282 13.56369</code></pre>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="reliability-and-validity.html#cb161-1" tabindex="-1"></a>(<span class="fl">13.56369</span> <span class="sc">-</span> <span class="fl">5.226282</span>)<span class="sc">/</span><span class="fl">1.68</span></span></code></pre></div>
<pre><code>## [1] 4.962743</code></pre>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="reliability-and-validity.html#cb163-1" tabindex="-1"></a><span class="co"># Prediction interval width is ~5 times our minimally clinically important </span></span>
<span id="cb163-2"><a href="reliability-and-validity.html#cb163-2" tabindex="-1"></a><span class="co"># change of 1.68 for HADS-A.</span></span>
<span id="cb163-3"><a href="reliability-and-validity.html#cb163-3" tabindex="-1"></a></span>
<span id="cb163-4"><a href="reliability-and-validity.html#cb163-4" tabindex="-1"></a>df <span class="sc">%&gt;%</span> </span>
<span id="cb163-5"><a href="reliability-and-validity.html#cb163-5" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> TP1, <span class="at">y =</span> TP2)) <span class="sc">+</span></span>
<span id="cb163-6"><a href="reliability-and-validity.html#cb163-6" tabindex="-1"></a>  <span class="co"># Color points conditionally</span></span>
<span id="cb163-7"><a href="reliability-and-validity.html#cb163-7" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color =</span> <span class="fu">ifelse</span>(TP2 <span class="sc">&gt;</span> TP1 <span class="sc">+</span> <span class="fl">1.68</span> <span class="sc">|</span> TP2 <span class="sc">&lt;</span> TP1 <span class="sc">-</span> <span class="fl">1.68</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;black&quot;</span>))) <span class="sc">+</span></span>
<span id="cb163-8"><a href="reliability-and-validity.html#cb163-8" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span> <span class="ot">=</span> <span class="st">&quot;red&quot;</span>, <span class="st">&quot;black&quot;</span> <span class="ot">=</span> <span class="st">&quot;black&quot;</span>), <span class="at">guide =</span> <span class="st">&quot;none&quot;</span>) <span class="sc">+</span></span>
<span id="cb163-9"><a href="reliability-and-validity.html#cb163-9" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> mod<span class="sc">$</span>coefficients[<span class="dv">1</span>], <span class="at">slope =</span> mod<span class="sc">$</span>coefficients[<span class="dv">2</span>]) <span class="sc">+</span></span>
<span id="cb163-10"><a href="reliability-and-validity.html#cb163-10" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb163-11"><a href="reliability-and-validity.html#cb163-11" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> pred[,<span class="dv">2</span>], <span class="at">ymax =</span> pred[,<span class="dv">3</span>]), <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span> </span>
<span id="cb163-12"><a href="reliability-and-validity.html#cb163-12" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;HADS-A and 95% Prediction Interval for TP2&quot;</span>) <span class="sc">+</span></span>
<span id="cb163-13"><a href="reliability-and-validity.html#cb163-13" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb163-14"><a href="reliability-and-validity.html#cb163-14" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;green&quot;</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span></span>
<span id="cb163-15"><a href="reliability-and-validity.html#cb163-15" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fl">1.68</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span></span>
<span id="cb163-16"><a href="reliability-and-validity.html#cb163-16" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="sc">-</span><span class="fl">1.68</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-12-2.png" width="672" /></p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="reliability-and-validity.html#cb165-1" tabindex="-1"></a><span class="co"># How often is TP2 within the MCIC of 1.68 points?---------</span></span>
<span id="cb165-2"><a href="reliability-and-validity.html#cb165-2" tabindex="-1"></a>df<span class="sc">$</span>abs_diff <span class="ot">&lt;-</span> <span class="fu">abs</span>(df<span class="sc">$</span>TP1 <span class="sc">-</span> df<span class="sc">$</span>TP2)</span>
<span id="cb165-3"><a href="reliability-and-validity.html#cb165-3" tabindex="-1"></a><span class="fu">hist</span>(df<span class="sc">$</span>abs_diff)</span>
<span id="cb165-4"><a href="reliability-and-validity.html#cb165-4" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">1.68</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-12-3.png" width="672" /></p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="reliability-and-validity.html#cb166-1" tabindex="-1"></a><span class="fu">table</span>(df<span class="sc">$</span>abs_diff <span class="sc">&gt;</span> <span class="fl">1.68</span>)<span class="sc">/</span><span class="fu">sum</span>(<span class="fu">table</span>(df<span class="sc">$</span>abs_diff <span class="sc">&gt;</span> <span class="fl">1.68</span>)) <span class="co"># </span></span></code></pre></div>
<pre><code>## 
##     FALSE      TRUE 
## 0.5368421 0.4631579</code></pre>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="reliability-and-validity.html#cb168-1" tabindex="-1"></a><span class="co"># -&gt; in ~46% of cases we detect a minimally clinically important change of 1.68 points.</span></span>
<span id="cb168-2"><a href="reliability-and-validity.html#cb168-2" tabindex="-1"></a><span class="co"># even though the underlying truth did not change.</span></span>
<span id="cb168-3"><a href="reliability-and-validity.html#cb168-3" tabindex="-1"></a></span>
<span id="cb168-4"><a href="reliability-and-validity.html#cb168-4" tabindex="-1"></a><span class="co"># This result is near random guessing</span></span></code></pre></div>
<p>The example shows that for the given value of ICC (<span class="math inline">\(&gt;0.8\)</span>) and MCID, the test retest reliability
is near random guessing with respect to detecting a change, since the second prediction is
very often outside the MCID (red dashed lines). Or in short: Even if Mary measures twice
with this ICC value, she will detect a clinically meaningful change in almost half of the cases,
although the underlying
truth did not change.</p>
<p>One could play around a little bit with the parameters here
(and maybe make the argument more rigorous),
but my guess would be that the main message remains stable.</p>
<p>What do you think? Can you find literature or logical arguments against this
simulation? I would be pleased to hear your thoughts.</p>
</div>
<div id="standard-error-of-measurement-sem" class="section level3 hasAnchor" number="2.1.7">
<h3><span class="header-section-number">2.1.7</span> Standard Error of Measurement (SEM)<a href="reliability-and-validity.html#standard-error-of-measurement-sem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Above, we defined the overall ICC as:</p>
<p><span class="math display">\[ICC = \frac{\sigma_{\alpha}^2}{\sigma_{\alpha}^2 + \sigma_{\varepsilon}^2}\]</span></p>
<p>The SEM is defined as: <span class="math inline">\(\sqrt{\sigma_{\varepsilon}^2}\)</span>.</p>
<p>This is a measure for the precision of the model. If this number is small,
we know the true but unknown score (<span class="math inline">\(\eta\)</span>) very precisely. As we have seen, for the
<span class="math inline">\(ICC_{agreement}\)</span> the error term includes the rater variability <span class="math inline">\(\sigma_{rater}\)</span>.</p>
<p>For ICC2 and 3 the model is the same and:</p>
<p><span class="math display">\[Y_{ij} = \eta_i + \beta_j + \varepsilon_i\]</span></p>
<p>For <span class="math inline">\(ICC_{agreement}\)</span>, the SEM is then:
<span class="math display">\[\sigma_{Y_i}^2 = \sigma_{\eta}^2 + \underbrace{\sigma_{\text{rater}}^2 + \sigma_{\varepsilon}^2}_{SEM_{agreement}^2}\]</span></p>
<p>For <span class="math inline">\(ICC_{consistency}\)</span>, the SEM is then:
<span class="math display">\[\sigma_{Y_i}^2 = \sigma_{\eta}^2 + \underbrace{\sigma_{\varepsilon}^2}_{SEM_{consistency}^2}\]</span></p>
<p>And since ICC 2 and 3 are based on the same model:
<span class="math display">\[SEM_{consistency} \le SEM_{agreement}\]</span>
(equality if there is no bias)</p>
<p>This yields the <strong>first method</strong> of getting the SEM: Estimate the
model (as we did above) and take the square root of the respective error term
(with or without the rater variability).</p>
<p>One can also show (excercise…) that we can find the <span class="math inline">\(SEM_{consistency}\)</span> by using
the standard deviation of the differences between the two measurements
of Peter and Mary:</p>
<p>We verify this immediately:</p>
<p><span class="math display">\[SEM_{consistency} = \frac{SD_{difference}}{\sqrt{2}}\]</span></p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="reliability-and-validity.html#cb169-1" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lmer</span>(ROM <span class="sc">~</span> (<span class="dv">1</span> <span class="sc">|</span> ID) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Rater), <span class="at">data =</span> df_long_bias)</span>
<span id="cb169-2"><a href="reliability-and-validity.html#cb169-2" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">VarCorr</span>(mod))</span></code></pre></div>
<pre><code>##  Groups   Name        Std.Dev.
##  ID       (Intercept) 16.4585 
##  Rater    (Intercept)  2.4886 
##  Residual              6.8961</code></pre>
<p><span class="math display">\[SEM_{consistency} = \sigma_{residual} = 6.8961\]</span></p>
<p>Let’s calculate the SEM from the differences between the two measurements:</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="reliability-and-validity.html#cb171-1" tabindex="-1"></a><span class="co"># SEM from differences</span></span>
<span id="cb171-2"><a href="reliability-and-validity.html#cb171-2" tabindex="-1"></a><span class="fu">sd</span>(df_long_bias<span class="sc">$</span>ROM[df_long_bias<span class="sc">$</span>Rater <span class="sc">==</span> <span class="st">&quot;ROMas.Mary&quot;</span>] <span class="sc">-</span></span>
<span id="cb171-3"><a href="reliability-and-validity.html#cb171-3" tabindex="-1"></a>   df_long_bias<span class="sc">$</span>ROM[df_long_bias<span class="sc">$</span>Rater <span class="sc">==</span> <span class="st">&quot;ROMas.Peter&quot;</span>]) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 6.896154</code></pre>
<p>This is a perfect match!</p>
</div>
<div id="bland-altman-plot" class="section level3 hasAnchor" number="2.1.8">
<h3><span class="header-section-number">2.1.8</span> Bland-Altman Plot<a href="reliability-and-validity.html#bland-altman-plot" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Bland-Altman plot is a graphical method to compare two measurements
techniques or raters. The goal is to spot systematic differences between the two
methods/raters. On the x axis, we plot the average of the two measurements
and on the y axis the difference between the two measurements. So, we could
for instance see larger variability in points with higher average values,
indicating that Peter and Mary disagree more for higher values.</p>
<p>Let’s quickly draw one and explain it:</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="reliability-and-validity.html#cb173-1" tabindex="-1"></a><span class="fu">library</span>(BlandAltmanLeh)</span>
<span id="cb173-2"><a href="reliability-and-validity.html#cb173-2" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb173-3"><a href="reliability-and-validity.html#cb173-3" tabindex="-1"></a>df_long_bias <span class="ot">&lt;-</span> <span class="fu">as.data.table</span>(df_long_bias)</span>
<span id="cb173-4"><a href="reliability-and-validity.html#cb173-4" tabindex="-1"></a><span class="co"># https://cran.r-project.org/web/packages/BlandAltmanLeh/BlandAltmanLeh.pdf</span></span>
<span id="cb173-5"><a href="reliability-and-validity.html#cb173-5" tabindex="-1"></a><span class="fu">bland.altman.plot</span>(df_long_bias[Rater <span class="sc">==</span> <span class="st">&quot;ROMas.Mary&quot;</span>, ]<span class="sc">$</span>ROM,</span>
<span id="cb173-6"><a href="reliability-and-validity.html#cb173-6" tabindex="-1"></a>                  df_long_bias[Rater <span class="sc">==</span> <span class="st">&quot;ROMas.Peter&quot;</span>, ]<span class="sc">$</span>ROM,</span>
<span id="cb173-7"><a href="reliability-and-validity.html#cb173-7" tabindex="-1"></a>                  <span class="at">two =</span> <span class="fl">1.96</span>,</span>
<span id="cb173-8"><a href="reliability-and-validity.html#cb173-8" tabindex="-1"></a>                  <span class="at">mode =</span> <span class="dv">1</span>,</span>
<span id="cb173-9"><a href="reliability-and-validity.html#cb173-9" tabindex="-1"></a>                  <span class="at">conf.int =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<pre><code>## NULL</code></pre>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="reliability-and-validity.html#cb175-1" tabindex="-1"></a><span class="co"># &quot;two&quot;: Lines are drawn &quot;two&quot; standard deviations from mean differences. </span></span>
<span id="cb175-2"><a href="reliability-and-validity.html#cb175-2" tabindex="-1"></a><span class="co"># This defaults to 1.96 for proper 95 percent confidence interval </span></span>
<span id="cb175-3"><a href="reliability-and-validity.html#cb175-3" tabindex="-1"></a><span class="co"># estimation but can be set to 2.0 for better agreement with e. g. </span></span>
<span id="cb175-4"><a href="reliability-and-validity.html#cb175-4" tabindex="-1"></a><span class="co"># the Bland Altman publication. </span></span>
<span id="cb175-5"><a href="reliability-and-validity.html#cb175-5" tabindex="-1"></a></span>
<span id="cb175-6"><a href="reliability-and-validity.html#cb175-6" tabindex="-1"></a><span class="co"># &quot;mode&quot;: if 1 then difference group1 minus group2 is used,</span></span>
<span id="cb175-7"><a href="reliability-and-validity.html#cb175-7" tabindex="-1"></a><span class="co"># if 2 then group2 minus group1 is used. Defaults to 1.</span></span></code></pre></div>
<p>… describe.. LOA … and so on.</p>
</div>
</div>
<div id="validity" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Validity<a href="reliability-and-validity.html#validity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>…</p>
</div>
<div id="todos" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> TODOS<a href="reliability-and-validity.html#todos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>After Rel/Val; Extension of Classical statistical Methods: Logistic Regression and others (see Gelman)</li>
<li>Last Chapter - Introduction to AI. Previous statistical analyses is a special case of neuronal networks.</li>
<li><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/cdoe.12617?casa_token=3IzTqt8cjzQAAAAA%3AhKH7i2yhPi9tIVbOz89JVMT2yuSuyhejGLcJqXVINfgo7kjxlkzzBhqu3iH0zW7ClZef0ivw790enq1I">table 2 fallacy</a></li>
<li>mention missing values, missingness mechanisms</li>
<li>Exercise: Show by simulation what Gelman talks about with significant p values. So I scan the data
for significant p values and then simulate data with the same effect size and see how often
I get significant p values. Especially the next effect would be probably smaller,
especially, if one did p-hacking! Calculate a priori probability for replication (def?).</li>
<li>Chapter: Sample size calculations for multivariate regression, Proportions, ICCs, t.test</li>
<li>AIC, BIC, cross-validation, Model selection (best subset, leaps….), Variable selection</li>
<li>More on bias variance tradeoff, show for polynomial regression?</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/01-Reliability_Validity.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
